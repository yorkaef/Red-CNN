{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 1: IMPORTS Y CONFIGURACIÓN INICIAL\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.models as models\n",
    "\n",
    "# Timm para modelos\n",
    "import timm\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Imbalanced-learn para SMOTE\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Albumentations para augmentations avanzadas\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# PIL\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🚀 Usando dispositivo: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memoria disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "# Configuración general\n",
    "class Config:\n",
    "    # Rutas\n",
    "    BASE_DIR = Path('skin-cancer-local')\n",
    "    IMAGE_DIRS = [\n",
    "        BASE_DIR / 'images' / 'imgs_part_1',\n",
    "        BASE_DIR / 'images' / 'imgs_part_2',\n",
    "        BASE_DIR / 'images' / 'imgs_part_3'\n",
    "    ]\n",
    "    METADATA_PATH = BASE_DIR / 'metadata.csv'\n",
    "    OUTPUT_DIR = Path('outputs')\n",
    "    MODELS_DIR = OUTPUT_DIR / 'models'\n",
    "    LOGS_DIR = OUTPUT_DIR / 'logs'\n",
    "    \n",
    "    # Parámetros de imagen\n",
    "    IMG_SIZE = 128  # Resolución alta para EfficientNetV2\n",
    "    IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "    IMG_STD = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    # Arquitectura\n",
    "    EFFICIENTNET_MODEL = 'tf_efficientnetv2_m'  # Modelo M para mejor performance\n",
    "    USE_PRETRAINED = True\n",
    "    DROP_PATH_RATE = 0.2\n",
    "    DROP_RATE = 0.3\n",
    "    \n",
    "    # TabTransformer\n",
    "    TAB_EMBED_DIM = 128\n",
    "    TAB_NUM_HEADS = 8\n",
    "    TAB_NUM_LAYERS = 6\n",
    "    TAB_DROPOUT = 0.3\n",
    "    \n",
    "    # Fusión\n",
    "    FUSION_HIDDEN_DIMS = [512, 256, 128]\n",
    "    FUSION_DROPOUT = 0.4\n",
    "    \n",
    "    # Entrenamiento\n",
    "    BATCH_SIZE = 16  # Ajustar según GPU\n",
    "    EPOCHS = 100\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    WARMUP_EPOCHS = 5\n",
    "    PATIENCE = 15\n",
    "    MIN_LR = 1e-7\n",
    "    \n",
    "    # Cross-validation\n",
    "    N_FOLDS = 5\n",
    "    \n",
    "    # Augmentation\n",
    "    MIXUP_ALPHA = 0.4\n",
    "    CUTMIX_ALPHA = 1.0\n",
    "    MIXUP_PROB = 0.5\n",
    "    \n",
    "    # TTA\n",
    "    TTA_TRANSFORMS = 5\n",
    "    \n",
    "    # Random seed\n",
    "    SEED = 42\n",
    "    \n",
    "    # Otros\n",
    "    NUM_WORKERS = 1\n",
    "    PIN_MEMORY = True\n",
    "    AMP_ENABLED = True  # Automatic Mixed Precision\n",
    "\n",
    "# Crear directorios\n",
    "Config.OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "Config.MODELS_DIR.mkdir(exist_ok=True)\n",
    "Config.LOGS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Set seeds para reproducibilidad\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(Config.SEED)\n",
    "\n",
    "print(\"✅ Configuración completada\")\n",
    "print(f\"   Tamaño de imagen: {Config.IMG_SIZE}x{Config.IMG_SIZE}\")\n",
    "print(f\"   Modelo: {Config.EFFICIENTNET_MODEL}\")\n",
    "print(f\"   Batch size: {Config.BATCH_SIZE}\")\n",
    "print(f\"   Épocas: {Config.EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ef0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 2: CARGA Y ANÁLISIS EXPLORATORIO DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "# Cargar metadata\n",
    "df = pd.read_csv(Config.METADATA_PATH)\n",
    "print(f\"📊 Dataset cargado: {len(df)} muestras\")\n",
    "print(f\"   Columnas: {df.shape[1]}\")\n",
    "\n",
    "# Análisis inicial\n",
    "print(\"\\n📋 Primeras filas:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n🔍 Información del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n📈 Estadísticas descriptivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Verificar imágenes existentes\n",
    "def find_image_path(img_id):\n",
    "    \"\"\"Busca la imagen en los directorios\"\"\"\n",
    "    for img_dir in Config.IMAGE_DIRS:\n",
    "        img_path = img_dir / img_id\n",
    "        if img_path.exists():\n",
    "            return str(img_path)\n",
    "    return None\n",
    "\n",
    "print(\"\\n🖼️ Verificando imágenes...\")\n",
    "df['image_path'] = df['img_id'].apply(find_image_path)\n",
    "missing_images = df['image_path'].isna().sum()\n",
    "print(f\"   Imágenes encontradas: {len(df) - missing_images}/{len(df)}\")\n",
    "if missing_images > 0:\n",
    "    print(f\"   ⚠️ Imágenes faltantes: {missing_images}\")\n",
    "    df = df.dropna(subset=['image_path'])\n",
    "\n",
    "# Análisis de la variable objetivo\n",
    "print(\"\\n🎯 Distribución de diagnósticos:\")\n",
    "diagnostic_counts = df['diagnostic'].value_counts()\n",
    "print(diagnostic_counts)\n",
    "print(f\"\\n   Clases únicas: {df['diagnostic'].nunique()}\")\n",
    "print(f\"   Desbalanceo máximo: {diagnostic_counts.max() / diagnostic_counts.min():.2f}x\")\n",
    "\n",
    "# Visualización de distribución\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "diagnostic_counts.plot(kind='bar', color='steelblue')\n",
    "plt.title('Distribución de Diagnósticos', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Diagnóstico')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(diagnostic_counts.values, labels=diagnostic_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Proporción de Clases', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.OUTPUT_DIR / 'class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Análisis de variables categóricas\n",
    "categorical_cols = ['smoke', 'drink', 'gender', 'background_father', 'background_mother',\n",
    "                   'skin_cancer_history', 'cancer_history', 'has_piped_water', \n",
    "                   'has_sewage_system', 'region', 'itch', 'grew', 'hurt', \n",
    "                   'changed', 'bleed', 'elevation', 'biopsed']\n",
    "\n",
    "print(\"\\n📊 Valores únicos en variables categóricas:\")\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        unique_vals = df[col].nunique()\n",
    "        missing = df[col].isna().sum()\n",
    "        print(f\"   {col}: {unique_vals} valores únicos, {missing} missing ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Análisis de variables numéricas\n",
    "numerical_cols = ['age', 'diameter_1', 'diameter_2', 'fitspatrick']\n",
    "\n",
    "print(\"\\n📊 Estadísticas de variables numéricas:\")\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n   {col}:\")\n",
    "        print(f\"      Media: {df[col].mean():.2f}\")\n",
    "        print(f\"      Mediana: {df[col].median():.2f}\")\n",
    "        print(f\"      Std: {df[col].std():.2f}\")\n",
    "        print(f\"      Missing: {df[col].isna().sum()} ({df[col].isna().sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Correlación con diagnóstico\n",
    "print(\"\\n🔗 Análisis de correlaciones con diagnóstico:\")\n",
    "df_encoded = df.copy()\n",
    "le_diag = LabelEncoder()\n",
    "df_encoded['diagnostic_encoded'] = le_diag.fit_transform(df['diagnostic'])\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns and df[col].notna().sum() > 0:\n",
    "        corr = df_encoded[[col, 'diagnostic_encoded']].corr().iloc[0, 1]\n",
    "        print(f\"   {col}: {corr:.3f}\")\n",
    "\n",
    "# Guardar información procesada\n",
    "print(f\"\\n💾 Dataset final: {len(df)} muestras con imágenes válidas\")\n",
    "df.to_csv(Config.OUTPUT_DIR / 'processed_metadata.csv', index=False)\n",
    "print(\"✅ Análisis exploratorio completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf351c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 3: PREPROCESAMIENTO AVANZADO DE METADATOS\n",
    "# ============================================================================\n",
    "\n",
    "class MetadataPreprocessor:\n",
    "    \"\"\"Preprocesador avanzado para metadatos tabulares\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_names = []\n",
    "        self.categorical_features = []\n",
    "        self.numerical_features = []\n",
    "        self.categorical_dims = {}  # Dimensiones para embedding\n",
    "        \n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"Ajusta y transforma los metadatos\"\"\"\n",
    "        df = df.copy()\n",
    "        processed_features = []\n",
    "        \n",
    "        # 1. VARIABLES CATEGÓRICAS\n",
    "        categorical_cols = [\n",
    "            'smoke', 'drink', 'gender', 'background_father', 'background_mother',\n",
    "            'pesticide', 'skin_cancer_history', 'cancer_history', \n",
    "            'has_piped_water', 'has_sewage_system', 'region',\n",
    "            'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation', 'biopsed'\n",
    "        ]\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            # Manejar missing values\n",
    "            df[col] = df[col].fillna('UNKNOWN')\n",
    "            \n",
    "            # Convertir booleanos\n",
    "            if df[col].dtype == 'bool':\n",
    "                df[col] = df[col].astype(str)\n",
    "            \n",
    "            # Label encoding\n",
    "            le = LabelEncoder()\n",
    "            df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "            \n",
    "            self.label_encoders[col] = le\n",
    "            self.categorical_features.append(f'{col}_encoded')\n",
    "            self.categorical_dims[f'{col}_encoded'] = len(le.classes_)\n",
    "            processed_features.append(f'{col}_encoded')\n",
    "        \n",
    "        # 2. VARIABLES NUMÉRICAS\n",
    "        numerical_cols = ['age', 'diameter_1', 'diameter_2', 'fitspatrick']\n",
    "        \n",
    "        for col in numerical_cols:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Imputación con mediana\n",
    "            median_val = df[col].median()\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "            \n",
    "            # Escalado robusto (mejor para outliers)\n",
    "            scaler = RobustScaler()\n",
    "            df[f'{col}_scaled'] = scaler.fit_transform(df[[col]])\n",
    "            \n",
    "            self.scalers[col] = scaler\n",
    "            self.numerical_features.append(f'{col}_scaled')\n",
    "            processed_features.append(f'{col}_scaled')\n",
    "        \n",
    "        # 3. FEATURE ENGINEERING\n",
    "        # Ratio de diámetros (si ambos existen)\n",
    "        if 'diameter_1' in df.columns and 'diameter_2' in df.columns:\n",
    "            df['diameter_ratio'] = df['diameter_1'] / (df['diameter_2'] + 1e-6)\n",
    "            df['diameter_ratio'] = df['diameter_ratio'].fillna(1.0)\n",
    "            \n",
    "            scaler_ratio = RobustScaler()\n",
    "            df['diameter_ratio_scaled'] = scaler_ratio.fit_transform(df[['diameter_ratio']])\n",
    "            \n",
    "            self.scalers['diameter_ratio'] = scaler_ratio\n",
    "            self.numerical_features.append('diameter_ratio_scaled')\n",
    "            processed_features.append('diameter_ratio_scaled')\n",
    "        \n",
    "        # Área aproximada\n",
    "        if 'diameter_1' in df.columns and 'diameter_2' in df.columns:\n",
    "            df['lesion_area'] = df['diameter_1'] * df['diameter_2']\n",
    "            df['lesion_area'] = df['lesion_area'].fillna(df['lesion_area'].median())\n",
    "            \n",
    "            scaler_area = RobustScaler()\n",
    "            df['lesion_area_scaled'] = scaler_area.fit_transform(df[['lesion_area']])\n",
    "            \n",
    "            self.scalers['lesion_area'] = scaler_area\n",
    "            self.numerical_features.append('lesion_area_scaled')\n",
    "            processed_features.append('lesion_area_scaled')\n",
    "        \n",
    "        # Age groups (binning)\n",
    "        if 'age' in df.columns:\n",
    "            df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 50, 65, 100], \n",
    "                                     labels=['0-18', '19-35', '36-50', '51-65', '66+'])\n",
    "            # Convertir a string antes de fillna para evitar error con categorías\n",
    "            df['age_group'] = df['age_group'].astype(str).replace('nan', 'UNKNOWN')\n",
    "            \n",
    "            le_age = LabelEncoder()\n",
    "            df['age_group_encoded'] = le_age.fit_transform(df['age_group'])\n",
    "            \n",
    "            self.label_encoders['age_group'] = le_age\n",
    "            self.categorical_features.append('age_group_encoded')\n",
    "            self.categorical_dims['age_group_encoded'] = len(le_age.classes_)\n",
    "            processed_features.append('age_group_encoded')\n",
    "        \n",
    "        # Conteo de síntomas (feature agregada)\n",
    "        symptom_cols = ['itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "        symptom_encoded = [f'{col}_encoded' for col in symptom_cols if f'{col}_encoded' in df.columns]\n",
    "        \n",
    "        if len(symptom_encoded) > 0:\n",
    "            df['symptom_count'] = df[symptom_encoded].sum(axis=1)\n",
    "            \n",
    "            scaler_symp = RobustScaler()\n",
    "            df['symptom_count_scaled'] = scaler_symp.fit_transform(df[['symptom_count']])\n",
    "            \n",
    "            self.scalers['symptom_count'] = scaler_symp\n",
    "            self.numerical_features.append('symptom_count_scaled')\n",
    "            processed_features.append('symptom_count_scaled')\n",
    "        \n",
    "        # Conteo de factores de riesgo\n",
    "        risk_cols = ['smoke_encoded', 'drink_encoded', 'skin_cancer_history_encoded', \n",
    "                     'cancer_history_encoded']\n",
    "        risk_encoded = [col for col in risk_cols if col in df.columns]\n",
    "        \n",
    "        if len(risk_encoded) > 0:\n",
    "            df['risk_score'] = df[risk_encoded].sum(axis=1)\n",
    "            \n",
    "            scaler_risk = RobustScaler()\n",
    "            df['risk_score_scaled'] = scaler_risk.fit_transform(df[['risk_score']])\n",
    "            \n",
    "            self.scalers['risk_score'] = scaler_risk\n",
    "            self.numerical_features.append('risk_score_scaled')\n",
    "            processed_features.append('risk_score_scaled')\n",
    "        \n",
    "        self.feature_names = processed_features\n",
    "        \n",
    "        # Retornar array con todas las features\n",
    "        X = df[processed_features].values.astype(np.float32)\n",
    "        \n",
    "        print(f\"✅ Preprocesamiento completado:\")\n",
    "        print(f\"   Features categóricas: {len(self.categorical_features)}\")\n",
    "        print(f\"   Features numéricas: {len(self.numerical_features)}\")\n",
    "        print(f\"   Total features: {len(self.feature_names)}\")\n",
    "        print(f\"   Shape: {X.shape}\")\n",
    "        \n",
    "        return X, df\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transforma nuevos datos usando los ajustes previos\"\"\"\n",
    "        df = df.copy()\n",
    "        processed_features = []\n",
    "        \n",
    "        # Categóricas\n",
    "        for col, le in self.label_encoders.items():\n",
    "            if col == 'age_group':\n",
    "                df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 50, 65, 100], \n",
    "                                        labels=['0-18', '19-35', '36-50', '51-65', '66+'])\n",
    "                # Convertir a string antes de fillna\n",
    "                df['age_group'] = df['age_group'].astype(str).replace('nan', 'UNKNOWN')\n",
    "                \n",
    "                # Manejar categorías no vistas\n",
    "                df['age_group'] = df['age_group'].apply(\n",
    "                    lambda x: x if x in le.classes_ else 'UNKNOWN'\n",
    "                )\n",
    "                df[f'{col}_encoded'] = le.transform(df['age_group'])\n",
    "            else:\n",
    "                df[col] = df[col].fillna('UNKNOWN')\n",
    "                if df[col].dtype == 'bool':\n",
    "                    df[col] = df[col].astype(str)\n",
    "                \n",
    "                # Manejar categorías no vistas\n",
    "                df[col] = df[col].apply(\n",
    "                    lambda x: x if x in le.classes_ else 'UNKNOWN'\n",
    "                )\n",
    "                df[f'{col}_encoded'] = le.transform(df[col].astype(str))\n",
    "        \n",
    "        # Numéricas\n",
    "        for col, scaler in self.scalers.items():\n",
    "            if col in ['diameter_ratio', 'lesion_area', 'symptom_count', 'risk_score']:\n",
    "                # Recalcular features derivadas\n",
    "                if col == 'diameter_ratio':\n",
    "                    df['diameter_ratio'] = df['diameter_1'] / (df['diameter_2'] + 1e-6)\n",
    "                    df['diameter_ratio'] = df['diameter_ratio'].fillna(1.0)\n",
    "                elif col == 'lesion_area':\n",
    "                    df['lesion_area'] = df['diameter_1'] * df['diameter_2']\n",
    "                    df['lesion_area'] = df['lesion_area'].fillna(df['lesion_area'].median())\n",
    "                elif col == 'symptom_count':\n",
    "                    symptom_cols = ['itch_encoded', 'grew_encoded', 'hurt_encoded', \n",
    "                                   'changed_encoded', 'bleed_encoded', 'elevation_encoded']\n",
    "                    symptom_encoded = [c for c in symptom_cols if c in df.columns]\n",
    "                    df['symptom_count'] = df[symptom_encoded].sum(axis=1)\n",
    "                elif col == 'risk_score':\n",
    "                    risk_cols = ['smoke_encoded', 'drink_encoded', \n",
    "                                'skin_cancer_history_encoded', 'cancer_history_encoded']\n",
    "                    risk_encoded = [c for c in risk_cols if c in df.columns]\n",
    "                    df['risk_score'] = df[risk_encoded].sum(axis=1)\n",
    "                \n",
    "                df[f'{col}_scaled'] = scaler.transform(df[[col]])\n",
    "            else:\n",
    "                orig_col = col\n",
    "                df[orig_col] = df[orig_col].fillna(df[orig_col].median())\n",
    "                df[f'{col}_scaled'] = scaler.transform(df[[orig_col]])\n",
    "        \n",
    "        X = df[self.feature_names].values.astype(np.float32)\n",
    "        return X, df\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "preprocessor = MetadataPreprocessor()\n",
    "X_metadata, df_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(f\"\\n📊 Metadata shape: {X_metadata.shape}\")\n",
    "print(f\"   Rango de valores: [{X_metadata.min():.3f}, {X_metadata.max():.3f}]\")\n",
    "\n",
    "# Guardar preprocessor\n",
    "import pickle\n",
    "with open(Config.OUTPUT_DIR / 'metadata_preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "print(\"✅ Preprocessor guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 4: AUGMENTATIONS AVANZADAS Y DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedAugmentation:\n",
    "    \"\"\"Augmentations de última generación para dermatología\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=512, mode='train'):\n",
    "        self.img_size = img_size\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                # Redimensionamiento\n",
    "                A.Resize(img_size, img_size),\n",
    "                \n",
    "                # Augmentations geométricas\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.1,\n",
    "                    scale_limit=0.2,\n",
    "                    rotate_limit=45,\n",
    "                    border_mode=0,\n",
    "                    p=0.7\n",
    "                ),\n",
    "                \n",
    "                # Distorsiones ópticas (importantes para lesiones)\n",
    "                A.OneOf([\n",
    "                    A.ElasticTransform(alpha=1, sigma=50, p=1.0),\n",
    "                    A.GridDistortion(num_steps=5, distort_limit=0.3, p=1.0),\n",
    "                    A.OpticalDistortion(distort_limit=0.5, shift_limit=0.5, p=1.0),\n",
    "                ], p=0.3),\n",
    "                \n",
    "                # Cambios de perspectiva\n",
    "                A.Perspective(scale=(0.05, 0.1), p=0.3),\n",
    "                \n",
    "                # Augmentations de color (críticas para dermatología)\n",
    "                A.OneOf([\n",
    "                    A.HueSaturationValue(\n",
    "                        hue_shift_limit=20,\n",
    "                        sat_shift_limit=30,\n",
    "                        val_shift_limit=20,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                    A.RGBShift(\n",
    "                        r_shift_limit=20,\n",
    "                        g_shift_limit=20,\n",
    "                        b_shift_limit=20,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                    A.ColorJitter(\n",
    "                        brightness=0.2,\n",
    "                        contrast=0.2,\n",
    "                        saturation=0.2,\n",
    "                        hue=0.1,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                ], p=0.8),\n",
    "                \n",
    "                # Simulación de condiciones de iluminación\n",
    "                A.OneOf([\n",
    "                    A.RandomBrightnessContrast(\n",
    "                        brightness_limit=0.3,\n",
    "                        contrast_limit=0.3,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                    A.RandomGamma(gamma_limit=(80, 120), p=1.0),\n",
    "                    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "                ], p=0.5),\n",
    "                \n",
    "                # Efectos de desenfoque (importante para diferentes calidades de imagen)\n",
    "                A.OneOf([\n",
    "                    A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                    A.MotionBlur(blur_limit=7, p=1.0),\n",
    "                    A.MedianBlur(blur_limit=7, p=1.0),\n",
    "                ], p=0.2),\n",
    "                \n",
    "                # Ruido (simula diferentes calidades de cámara)\n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
    "                    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1.0),\n",
    "                    A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=1.0),\n",
    "                ], p=0.2),\n",
    "                \n",
    "                # Compresión JPEG (realista)\n",
    "                A.ImageCompression(quality_lower=75, quality_upper=100, p=0.3),\n",
    "                \n",
    "                # Cutout avanzado\n",
    "                A.CoarseDropout(\n",
    "                    max_holes=8,\n",
    "                    max_height=int(img_size * 0.15),\n",
    "                    max_width=int(img_size * 0.15),\n",
    "                    min_holes=1,\n",
    "                    fill_value=0,\n",
    "                    p=0.3\n",
    "                ),\n",
    "                \n",
    "                # Normalización\n",
    "                A.Normalize(\n",
    "                    mean=Config.IMG_MEAN,\n",
    "                    std=Config.IMG_STD,\n",
    "                    max_pixel_value=255.0\n",
    "                ),\n",
    "                \n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        \n",
    "        else:  # val/test\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.Normalize(\n",
    "                    mean=Config.IMG_MEAN,\n",
    "                    std=Config.IMG_STD,\n",
    "                    max_pixel_value=255.0\n",
    "                ),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = np.array(Image.open(image).convert('RGB'))\n",
    "        elif isinstance(image, Image.Image):\n",
    "            image = np.array(image.convert('RGB'))\n",
    "        \n",
    "        return self.transform(image=image)['image']\n",
    "\n",
    "\n",
    "class TTATransform:\n",
    "    \"\"\"Test-Time Augmentation transforms\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=512):\n",
    "        self.img_size = img_size\n",
    "        self.transforms = [\n",
    "            # Original\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Flip horizontal\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.HorizontalFlip(p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Flip vertical\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.VerticalFlip(p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Rotate 90\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.Rotate(limit=90, p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Brightness\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = np.array(Image.open(image).convert('RGB'))\n",
    "        elif isinstance(image, Image.Image):\n",
    "            image = np.array(image.convert('RGB'))\n",
    "        \n",
    "        return [t(image=image)['image'] for t in self.transforms]\n",
    "\n",
    "\n",
    "class SkinCancerDataset(Dataset):\n",
    "    \"\"\"Dataset avanzado con soporte para mixup y cutmix\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, metadata, labels, transform=None, mode='train'):\n",
    "        self.image_paths = image_paths\n",
    "        self.metadata = torch.FloatTensor(metadata)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Cargar imagen\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = T.ToTensor()(image)\n",
    "        \n",
    "        metadata = self.metadata[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "\n",
    "def mixup_data(x_img, x_meta, y, alpha=0.4):\n",
    "    \"\"\"Mixup augmentation para imagen y metadata\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x_img.size(0)\n",
    "    index = torch.randperm(batch_size).to(x_img.device)\n",
    "    \n",
    "    mixed_img = lam * x_img + (1 - lam) * x_img[index]\n",
    "    mixed_meta = lam * x_meta + (1 - lam) * x_meta[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_img, mixed_meta, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def cutmix_data(x_img, x_meta, y, alpha=1.0):\n",
    "    \"\"\"CutMix augmentation\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x_img.size(0)\n",
    "    index = torch.randperm(batch_size).to(x_img.device)\n",
    "    \n",
    "    _, _, h, w = x_img.size()\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(w * cut_rat)\n",
    "    cut_h = int(h * cut_rat)\n",
    "    \n",
    "    cx = np.random.randint(w)\n",
    "    cy = np.random.randint(h)\n",
    "    \n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, w)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, h)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, w)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, h)\n",
    "    \n",
    "    mixed_img = x_img.clone()\n",
    "    mixed_img[:, :, bby1:bby2, bbx1:bbx2] = x_img[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    \n",
    "    # Metadata no se mezcla en CutMix\n",
    "    mixed_meta = x_meta\n",
    "    \n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (w * h))\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_img, mixed_meta, y_a, y_b, lam\n",
    "\n",
    "\n",
    "print(\"✅ Augmentations y Dataset configurados\")\n",
    "print(f\"   Políticas de augmentation: Train (avanzado) / Val (básico)\")\n",
    "print(f\"   TTA transforms: {Config.TTA_TRANSFORMS}\")\n",
    "print(f\"   Mixup alpha: {Config.MIXUP_ALPHA}\")\n",
    "print(f\"   CutMix alpha: {Config.CUTMIX_ALPHA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 5: ARQUITECTURA DEL MODELO - FUSIÓN MULTIMODAL\n",
    "# ============================================================================\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "    \"\"\"Transformer para datos tabulares con embeddings categóricos\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 categorical_dims,\n",
    "                 numerical_features,\n",
    "                 embed_dim=128,\n",
    "                 num_heads=8,\n",
    "                 num_layers=6,\n",
    "                 dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.categorical_dims = categorical_dims\n",
    "        self.num_numerical = numerical_features\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Embeddings para features categóricas\n",
    "        self.categorical_embeddings = nn.ModuleDict({\n",
    "            name: nn.Embedding(dim + 1, embed_dim)\n",
    "            for name, dim in categorical_dims.items()\n",
    "        })\n",
    "        \n",
    "        # Proyección para features numéricas\n",
    "        if self.num_numerical > 0:\n",
    "            self.numerical_projection = nn.Sequential(\n",
    "                nn.Linear(self.num_numerical, embed_dim),\n",
    "                nn.LayerNorm(embed_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        \n",
    "        # Positional encoding\n",
    "        total_features = len(categorical_dims) + (1 if self.num_numerical > 0 else 0)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, total_features, embed_dim))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=embed_dim * 4,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Layer normalization final\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x, cat_indices):\n",
    "        \"\"\"\n",
    "        x: tensor [batch, total_features]\n",
    "        cat_indices: dict con índices de cada feature categórica\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        # Embeddings categóricos\n",
    "        for name, dim in self.categorical_dims.items():\n",
    "            idx = cat_indices[name]\n",
    "            cat_vals = x[:, idx].long()\n",
    "            \n",
    "            # ⚠️ CLIP CRÍTICO: Asegurar que estén en rango [0, dim-1]\n",
    "            cat_vals = torch.clamp(cat_vals, 0, dim - 1)\n",
    "            \n",
    "            emb = self.categorical_embeddings[name](cat_vals)\n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Proyección de features numéricas\n",
    "        if self.num_numerical > 0:\n",
    "            num_start = len(self.categorical_dims)\n",
    "            num_features = x[:, num_start:]\n",
    "            num_emb = self.numerical_projection(num_features)\n",
    "            embeddings.append(num_emb)\n",
    "        \n",
    "        # Stack embeddings\n",
    "        x = torch.stack(embeddings, dim=1)  # [batch, n_features, embed_dim]\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_embedding\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.mean(dim=1)  # [batch, embed_dim]\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class MultimodalSkinCancerModel(nn.Module):\n",
    "    \"\"\"Modelo multimodal: EfficientNetV2 + TabTransformer + Late Fusion\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_classes,\n",
    "                 categorical_dims,\n",
    "                 num_numerical_features,\n",
    "                 img_model_name='tf_efficientnetv2_m',\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ===== BRANCH 1: IMAGE MODEL (EfficientNetV2) =====\n",
    "        self.image_model = timm.create_model(\n",
    "            img_model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,  # Remove classifier\n",
    "            drop_rate=Config.DROP_RATE,\n",
    "            drop_path_rate=Config.DROP_PATH_RATE\n",
    "        )\n",
    "        \n",
    "        # Obtener dimensión de salida\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, Config.IMG_SIZE, Config.IMG_SIZE)\n",
    "            img_features = self.image_model(dummy_input)\n",
    "            self.img_feature_dim = img_features.shape[1]\n",
    "        \n",
    "        print(f\"✅ EfficientNetV2 cargado: {self.img_feature_dim} features\")\n",
    "        \n",
    "        # ===== BRANCH 2: METADATA MODEL (TabTransformer) =====\n",
    "        self.metadata_model = TabTransformer(\n",
    "            categorical_dims=categorical_dims,\n",
    "            numerical_features=num_numerical_features,\n",
    "            embed_dim=Config.TAB_EMBED_DIM,\n",
    "            num_heads=Config.TAB_NUM_HEADS,\n",
    "            num_layers=Config.TAB_NUM_LAYERS,\n",
    "            dropout=Config.TAB_DROPOUT\n",
    "        )\n",
    "        \n",
    "        self.meta_feature_dim = Config.TAB_EMBED_DIM\n",
    "        \n",
    "        print(f\"✅ TabTransformer construido: {self.meta_feature_dim} features\")\n",
    "        \n",
    "        # ===== FUSION HEAD =====\n",
    "        fusion_input_dim = self.img_feature_dim + self.meta_feature_dim\n",
    "        \n",
    "        fusion_layers = []\n",
    "        prev_dim = fusion_input_dim\n",
    "        \n",
    "        for hidden_dim in Config.FUSION_HIDDEN_DIMS:\n",
    "            fusion_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(Config.FUSION_DROPOUT)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.fusion_head = nn.Sequential(*fusion_layers)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(prev_dim, num_classes)\n",
    "        \n",
    "        # Attention weights para fusión interpretable (opcional)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(fusion_input_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Fusion head: {fusion_input_dim} -> {prev_dim} -> {num_classes}\")\n",
    "        \n",
    "        # Inicialización de pesos\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Inicialización Xavier/Kaiming\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, images, metadata, cat_indices):\n",
    "        \"\"\"\n",
    "        images: [batch, 3, H, W]\n",
    "        metadata: [batch, n_features]\n",
    "        cat_indices: dict con índices de features categóricas\n",
    "        \"\"\"\n",
    "        # Image features\n",
    "        img_features = self.image_model(images)  # [batch, img_dim]\n",
    "        \n",
    "        # Metadata features\n",
    "        meta_features = self.metadata_model(metadata, cat_indices)  # [batch, meta_dim]\n",
    "        \n",
    "        # Concatenate\n",
    "        fused = torch.cat([img_features, meta_features], dim=1)\n",
    "        \n",
    "        # Optional: Attention-weighted fusion\n",
    "        # att_weights = self.attention(fused)  # [batch, 2]\n",
    "        # img_weight = att_weights[:, 0:1]\n",
    "        # meta_weight = att_weights[:, 1:2]\n",
    "        # fused = torch.cat([\n",
    "        #     img_features * img_weight, \n",
    "        #     meta_features * meta_weight\n",
    "        # ], dim=1)\n",
    "        \n",
    "        # Fusion head\n",
    "        fused = self.fusion_head(fused)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(fused)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def freeze_image_backbone(self):\n",
    "        \"\"\"Congela el backbone de imagen para fine-tuning\"\"\"\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_image_backbone(self):\n",
    "        \"\"\"Descongela el backbone de imagen\"\"\"\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "# Función para crear el modelo\n",
    "def create_model(num_classes, categorical_dims, num_numerical_features):\n",
    "    \"\"\"Factory function para crear el modelo\"\"\"\n",
    "    model = MultimodalSkinCancerModel(\n",
    "        num_classes=num_classes,\n",
    "        categorical_dims=categorical_dims,\n",
    "        num_numerical_features=num_numerical_features,\n",
    "        img_model_name=Config.EFFICIENTNET_MODEL,\n",
    "        pretrained=Config.USE_PRETRAINED\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Contar parámetros\n",
    "def count_parameters(model):\n",
    "    \"\"\"Cuenta parámetros entrenables y totales\"\"\"\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    return trainable, total\n",
    "\n",
    "\n",
    "print(\"✅ Arquitectura del modelo definida\")\n",
    "print(f\"   Modelo de imagen: {Config.EFFICIENTNET_MODEL}\")\n",
    "print(f\"   TabTransformer: {Config.TAB_NUM_LAYERS} layers, {Config.TAB_NUM_HEADS} heads\")\n",
    "print(f\"   Fusion dims: {Config.FUSION_HIDDEN_DIMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 6: LOSS FUNCTIONS Y MÉTRICAS AVANZADAS\n",
    "# ============================================================================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss para desbalanceo de clases\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"Cross Entropy con Label Smoothing\"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        n_classes = pred.size(1)\n",
    "        log_pred = F.log_softmax(pred, dim=1)\n",
    "        \n",
    "        loss = -log_pred.sum(dim=1).mean()\n",
    "        nll = F.nll_loss(log_pred, target, reduction='mean')\n",
    "        \n",
    "        return self.smoothing * (loss / n_classes) + (1 - self.smoothing) * nll\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combinación de múltiples loss functions\"\"\"\n",
    "    \n",
    "    def __init__(self, class_weights=None, focal_gamma=2.0, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Focal loss para desbalanceo\n",
    "        self.focal_loss = FocalLoss(alpha=class_weights, gamma=focal_gamma)\n",
    "        \n",
    "        # Label smoothing para regularización\n",
    "        self.ls_loss = LabelSmoothingCrossEntropy(smoothing=label_smoothing)\n",
    "        \n",
    "        # Pesos\n",
    "        self.focal_weight = 0.7\n",
    "        self.ls_weight = 0.3\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        focal = self.focal_loss(pred, target)\n",
    "        ls = self.ls_loss(pred, target)\n",
    "        \n",
    "        return self.focal_weight * focal + self.ls_weight * ls\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Loss para mixup/cutmix\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "class MetricsTracker:\n",
    "    \"\"\"Seguimiento de métricas durante entrenamiento\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, class_names):\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        self.losses = []\n",
    "    \n",
    "    def update(self, preds, targets, loss):\n",
    "        \"\"\"\n",
    "        preds: logits [batch, num_classes]\n",
    "        targets: labels [batch]\n",
    "        loss: scalar\n",
    "        \"\"\"\n",
    "        pred_classes = torch.argmax(preds, dim=1)\n",
    "        \n",
    "        self.predictions.extend(pred_classes.cpu().numpy())\n",
    "        self.targets.extend(targets.cpu().numpy())\n",
    "        self.losses.append(loss)\n",
    "    \n",
    "    def compute(self):\n",
    "        \"\"\"Calcula todas las métricas\"\"\"\n",
    "        preds = np.array(self.predictions)\n",
    "        targets = np.array(self.targets)\n",
    "        \n",
    "        # Accuracy\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        \n",
    "        # Métricas por clase\n",
    "        precision = precision_score(targets, preds, average='weighted', zero_division=0)\n",
    "        recall = recall_score(targets, preds, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(targets, preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        # Métricas macro (importante para desbalanceo)\n",
    "        precision_macro = precision_score(targets, preds, average='macro', zero_division=0)\n",
    "        recall_macro = recall_score(targets, preds, average='macro', zero_division=0)\n",
    "        f1_macro = f1_score(targets, preds, average='macro', zero_division=0)\n",
    "        \n",
    "        # Loss promedio\n",
    "        avg_loss = np.mean(self.losses)\n",
    "        \n",
    "        # Matriz de confusión\n",
    "        cm = confusion_matrix(targets, preds)\n",
    "        \n",
    "        # Per-class metrics\n",
    "        per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "        \n",
    "        metrics = {\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'confusion_matrix': cm,\n",
    "            'per_class_accuracy': dict(zip(self.class_names, per_class_acc))\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def print_metrics(self, metrics, prefix=''):\n",
    "        \"\"\"Imprime métricas de forma legible\"\"\"\n",
    "        print(f\"\\n{prefix} Métricas:\")\n",
    "        print(f\"  Loss: {metrics['loss']:.4f}\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Precision (weighted): {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall (weighted): {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1-Score (weighted): {metrics['f1']:.4f}\")\n",
    "        print(f\"  Precision (macro): {metrics['precision_macro']:.4f}\")\n",
    "        print(f\"  Recall (macro): {metrics['recall_macro']:.4f}\")\n",
    "        print(f\"  F1-Score (macro): {metrics['f1_macro']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n  Accuracy por clase:\")\n",
    "        for class_name, acc in metrics['per_class_accuracy'].items():\n",
    "            print(f\"    {class_name}: {acc:.4f}\")\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, save_path=None):\n",
    "    \"\"\"Visualiza matriz de confusión\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Normalizar\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cm_norm,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='Blues',\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        cbar_kws={'label': 'Proporción'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Matriz de Confusión Normalizada', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Verdadero', fontsize=12)\n",
    "    plt.xlabel('Predicho', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_path=None):\n",
    "    \"\"\"Visualiza historial de entrenamiento\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val', linewidth=2)\n",
    "    axes[0, 0].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history['train_acc'], label='Train', linewidth=2)\n",
    "    axes[0, 1].plot(history['val_acc'], label='Val', linewidth=2)\n",
    "    axes[0, 1].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 0].plot(history['train_f1'], label='Train', linewidth=2)\n",
    "    axes[1, 0].plot(history['val_f1'], label='Val', linewidth=2)\n",
    "    axes[1, 0].set_title('F1-Score (Weighted)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('F1-Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[1, 1].plot(history['lr'], linewidth=2, color='green')\n",
    "    axes[1, 1].set_title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('LR')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"✅ Loss functions y métricas configuradas\")\n",
    "print(\"   - Focal Loss (para desbalanceo)\")\n",
    "print(\"   - Label Smoothing (regularización)\")\n",
    "print(\"   - Combined Loss (0.7*Focal + 0.3*LS)\")\n",
    "print(\"   - Métricas: Accuracy, Precision, Recall, F1 (weighted y macro)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a6df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 7: PREPARACIÓN Y BALANCEO DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "# Encode target labels\n",
    "le_target = LabelEncoder()\n",
    "df_processed['diagnostic_encoded'] = le_target.fit_transform(df_processed['diagnostic'])\n",
    "\n",
    "class_names = le_target.classes_\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"🎯 Clases detectadas: {num_classes}\")\n",
    "for i, name in enumerate(class_names):\n",
    "    count = (df_processed['diagnostic_encoded'] == i).sum()\n",
    "    print(f\"   {i}: {name} - {count} muestras\")\n",
    "\n",
    "# Preparar arrays\n",
    "image_paths = df_processed['image_path'].values\n",
    "labels = df_processed['diagnostic_encoded'].values\n",
    "\n",
    "# Crear índices de features categóricas para TabTransformer\n",
    "cat_feature_indices = {}\n",
    "idx = 0\n",
    "for feat in preprocessor.categorical_features:\n",
    "    cat_feature_indices[feat] = idx\n",
    "    idx += 1\n",
    "\n",
    "print(f\"\\n📊 Features para TabTransformer:\")\n",
    "print(f\"   Categóricas: {len(preprocessor.categorical_features)}\")\n",
    "print(f\"   Numéricas: {len(preprocessor.numerical_features)}\")\n",
    "print(f\"   Total: {X_metadata.shape[1]}\")\n",
    "\n",
    "# Split estratificado train/val/test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    np.arange(len(image_paths)),\n",
    "    labels,\n",
    "    test_size=0.15,\n",
    "    stratify=labels,\n",
    "    random_state=Config.SEED\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.15 / 0.85,  # ~15% of total\n",
    "    stratify=y_temp,\n",
    "    random_state=Config.SEED\n",
    ")\n",
    "\n",
    "print(f\"\\n📦 Splits:\")\n",
    "print(f\"   Train: {len(X_train)} ({len(X_train)/len(labels)*100:.1f}%)\")\n",
    "print(f\"   Val: {len(X_val)} ({len(X_val)/len(labels)*100:.1f}%)\")\n",
    "print(f\"   Test: {len(X_test)} ({len(X_test)/len(labels)*100:.1f}%)\")\n",
    "\n",
    "# Distribución por clase en cada split\n",
    "print(f\"\\n📊 Distribución por split:\")\n",
    "for split_name, split_indices in [('Train', X_train), ('Val', X_val), ('Test', X_test)]:\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    split_labels = labels[split_indices]\n",
    "    for i, name in enumerate(class_names):\n",
    "        count = (split_labels == i).sum()\n",
    "        pct = count / len(split_labels) * 100\n",
    "        print(f\"   {name}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Calcular class weights para loss\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(f\"\\n⚖️ Class weights calculados:\")\n",
    "for i, (name, weight) in enumerate(zip(class_names, class_weights)):\n",
    "    print(f\"   {name}: {weight:.3f}\")\n",
    "\n",
    "# OPCIONAL: SMOTE para balancear train set (solo si desbalanceo es extremo)\n",
    "# Si el desbalanceo es > 10x, aplicar SMOTE\n",
    "max_samples = np.max(np.bincount(y_train))\n",
    "min_samples = np.min(np.bincount(y_train))\n",
    "imbalance_ratio = max_samples / min_samples\n",
    "\n",
    "print(f\"\\n📊 Ratio de desbalanceo en train: {imbalance_ratio:.2f}x\")\n",
    "\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"⚠️ Desbalanceo alto detectado. Aplicando SMOTE...\")\n",
    "    \n",
    "    # SMOTE solo se puede aplicar a metadata, no a imágenes\n",
    "    # Estrategia: oversample los índices\n",
    "    \n",
    "    # Crear estrategia de oversampling\n",
    "    sampling_strategy = {}\n",
    "    for i in range(num_classes):\n",
    "        count = (y_train == i).sum()\n",
    "        if count < max_samples * 0.5:  # Clases muy minoritarias\n",
    "            sampling_strategy[i] = int(max_samples * 0.7)\n",
    "    \n",
    "    if len(sampling_strategy) > 0:\n",
    "        smote = SMOTE(\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            random_state=Config.SEED,\n",
    "            k_neighbors=min(5, min_samples - 1)\n",
    "        )\n",
    "        \n",
    "        # Aplicar SMOTE\n",
    "        X_meta_train = X_metadata[X_train]\n",
    "        X_meta_resampled, y_train_resampled = smote.fit_resample(X_meta_train, y_train)\n",
    "        \n",
    "        # Ahora necesitamos duplicar las imágenes correspondientes\n",
    "        # Para esto, mapeamos los índices originales\n",
    "        original_indices = X_train.copy()\n",
    "        \n",
    "        # Encontrar qué muestras fueron duplicadas\n",
    "        n_original = len(X_train)\n",
    "        n_resampled = len(y_train_resampled)\n",
    "        n_synthetic = n_resampled - n_original\n",
    "        \n",
    "        print(f\"   Muestras originales: {n_original}\")\n",
    "        print(f\"   Muestras después de SMOTE: {n_resampled}\")\n",
    "        print(f\"   Muestras sintéticas: {n_synthetic}\")\n",
    "        \n",
    "        # Para las sintéticas, asignamos la imagen más cercana de la misma clase\n",
    "        # (simplificación: usar índices aleatorios de la misma clase)\n",
    "        synthetic_indices = []\n",
    "        for i in range(n_synthetic):\n",
    "            # Obtener clase de la muestra sintética\n",
    "            synthetic_label = y_train_resampled[n_original + i]\n",
    "            # Seleccionar índice aleatorio de la misma clase\n",
    "            class_indices = original_indices[y_train == synthetic_label]\n",
    "            synthetic_idx = np.random.choice(class_indices)\n",
    "            synthetic_indices.append(synthetic_idx)\n",
    "        \n",
    "        # Combinar índices\n",
    "        X_train_final = np.concatenate([original_indices, synthetic_indices])\n",
    "        y_train_final = y_train_resampled\n",
    "        X_meta_train_final = X_meta_resampled\n",
    "        \n",
    "        print(f\"\\n✅ SMOTE aplicado. Nuevo tamaño de train: {len(X_train_final)}\")\n",
    "        print(\"   Distribución después de SMOTE:\")\n",
    "        for i, name in enumerate(class_names):\n",
    "            count = (y_train_final == i).sum()\n",
    "            print(f\"   {name}: {count}\")\n",
    "    else:\n",
    "        print(\"   No se requiere SMOTE (desbalanceo moderado)\")\n",
    "        X_train_final = X_train\n",
    "        y_train_final = y_train\n",
    "        X_meta_train_final = X_metadata[X_train]\n",
    "else:\n",
    "    print(\"✅ Desbalanceo aceptable. No se aplica SMOTE.\")\n",
    "    X_train_final = X_train\n",
    "    y_train_final = y_train\n",
    "    X_meta_train_final = X_metadata[X_train]\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = SkinCancerDataset(\n",
    "    image_paths=image_paths[X_train_final],\n",
    "    metadata=X_meta_train_final,\n",
    "    labels=y_train_final,\n",
    "    transform=AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='train'),\n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "val_dataset = SkinCancerDataset(\n",
    "    image_paths=image_paths[X_val],\n",
    "    metadata=X_metadata[X_val],\n",
    "    labels=y_val,\n",
    "    transform=AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='val'),\n",
    "    mode='val'\n",
    ")\n",
    "\n",
    "test_dataset = SkinCancerDataset(\n",
    "    image_paths=image_paths[X_test],\n",
    "    metadata=X_metadata[X_test],\n",
    "    labels=y_test,\n",
    "    transform=AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='val'),\n",
    "    mode='test'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Datasets creados:\")\n",
    "print(f\"   Train: {len(train_dataset)}\")\n",
    "print(f\"   Val: {len(val_dataset)}\")\n",
    "print(f\"   Test: {len(test_dataset)}\")\n",
    "\n",
    "# Crear dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    pin_memory=Config.PIN_MEMORY,\n",
    "    drop_last=True  # Para mixup/cutmix\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    pin_memory=Config.PIN_MEMORY\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    pin_memory=Config.PIN_MEMORY\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ DataLoaders creados:\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Guardar información para posterior uso\n",
    "dataset_info = {\n",
    "    'class_names': class_names.tolist(),\n",
    "    'num_classes': num_classes,\n",
    "    'class_weights': class_weights.cpu().numpy().tolist(),\n",
    "    'train_size': len(train_dataset),\n",
    "    'val_size': len(val_dataset),\n",
    "    'test_size': len(test_dataset),\n",
    "    'cat_feature_indices': cat_feature_indices,\n",
    "    'categorical_dims': preprocessor.categorical_dims\n",
    "}\n",
    "\n",
    "with open(Config.OUTPUT_DIR / 'dataset_info.json', 'w') as f:\n",
    "    json.dump(dataset_info, f, indent=2)\n",
    "\n",
    "print(\"\\n💾 Información del dataset guardada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 8: TRAINING LOOP COMPLETO CON TÉCNICAS AVANZADAS\n",
    "# ============================================================================\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Trainer avanzado con todas las optimizaciones\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, val_loader, criterion, optimizer, \n",
    "                 scheduler, cat_indices, device, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.cat_indices = cat_indices\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        \n",
    "        # Gradient scaler para AMP\n",
    "        self.scaler = torch.cuda.amp.GradScaler() if config.AMP_ENABLED else None\n",
    "        \n",
    "        # History\n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'train_f1': [], 'val_f1': [],\n",
    "            'lr': []\n",
    "        }\n",
    "        \n",
    "        # Best model tracking\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_val_f1 = 0.0\n",
    "        self.best_epoch = 0\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Entrena una época\"\"\"\n",
    "        self.model.train()\n",
    "        metrics_tracker = MetricsTracker(len(class_names), class_names)\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch+1}/{self.config.EPOCHS} [Train]')\n",
    "        \n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            images = batch['image'].to(self.device)\n",
    "            metadata = batch['metadata'].to(self.device)\n",
    "            labels = batch['label'].to(self.device)\n",
    "            \n",
    "            # Aplicar mixup/cutmix con probabilidad\n",
    "            use_mixup = np.random.rand() < self.config.MIXUP_PROB\n",
    "            \n",
    "            if use_mixup:\n",
    "                if np.random.rand() < 0.5:  # 50% mixup, 50% cutmix\n",
    "                    images, metadata, labels_a, labels_b, lam = mixup_data(\n",
    "                        images, metadata, labels, alpha=self.config.MIXUP_ALPHA\n",
    "                    )\n",
    "                else:\n",
    "                    images, metadata, labels_a, labels_b, lam = cutmix_data(\n",
    "                        images, metadata, labels, alpha=self.config.CUTMIX_ALPHA\n",
    "                    )\n",
    "            \n",
    "            # Forward pass con AMP\n",
    "            with torch.cuda.amp.autocast(enabled=self.config.AMP_ENABLED):\n",
    "                logits = self.model(images, metadata, self.cat_indices)\n",
    "                \n",
    "                if use_mixup:\n",
    "                    loss = mixup_criterion(self.criterion, logits, labels_a, labels_b, lam)\n",
    "                else:\n",
    "                    loss = self.criterion(logits, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            if self.scaler is not None:\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            if use_mixup:\n",
    "                # Para mixup, usamos las etiquetas originales para métricas\n",
    "                metrics_tracker.update(logits.detach(), labels_a, loss.item())\n",
    "            else:\n",
    "                metrics_tracker.update(logits.detach(), labels, loss.item())\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Compute epoch metrics\n",
    "        train_metrics = metrics_tracker.compute()\n",
    "        \n",
    "        return train_metrics\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        \"\"\"Valida el modelo\"\"\"\n",
    "        self.model.eval()\n",
    "        metrics_tracker = MetricsTracker(len(class_names), class_names)\n",
    "        \n",
    "        pbar = tqdm(self.val_loader, desc=f'Epoch {epoch+1}/{self.config.EPOCHS} [Val]')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in pbar:\n",
    "                images = batch['image'].to(self.device)\n",
    "                metadata = batch['metadata'].to(self.device)\n",
    "                labels = batch['label'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                with torch.cuda.amp.autocast(enabled=self.config.AMP_ENABLED):\n",
    "                    logits = self.model(images, metadata, self.cat_indices)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "                \n",
    "                # Update metrics\n",
    "                metrics_tracker.update(logits, labels, loss.item())\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Compute epoch metrics\n",
    "        val_metrics = metrics_tracker.compute()\n",
    "        \n",
    "        return val_metrics\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Loop de entrenamiento completo\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"🚀 INICIANDO ENTRENAMIENTO\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Epoch {epoch+1}/{self.config.EPOCHS}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Train\n",
    "            train_metrics = self.train_epoch(epoch)\n",
    "            \n",
    "            # Validate\n",
    "            val_metrics = self.validate(epoch)\n",
    "            \n",
    "            # Scheduler step\n",
    "            if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                self.scheduler.step(val_metrics['loss'])\n",
    "            else:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Update history\n",
    "            self.history['train_loss'].append(train_metrics['loss'])\n",
    "            self.history['val_loss'].append(val_metrics['loss'])\n",
    "            self.history['train_acc'].append(train_metrics['accuracy'])\n",
    "            self.history['val_acc'].append(val_metrics['accuracy'])\n",
    "            self.history['train_f1'].append(train_metrics['f1'])\n",
    "            self.history['val_f1'].append(val_metrics['f1'])\n",
    "            self.history['lr'].append(current_lr)\n",
    "            \n",
    "            # Print metrics\n",
    "            print(f\"\\n📊 TRAIN - Loss: {train_metrics['loss']:.4f} | \"\n",
    "                  f\"Acc: {train_metrics['accuracy']:.4f} | F1: {train_metrics['f1']:.4f}\")\n",
    "            print(f\"📊 VAL   - Loss: {val_metrics['loss']:.4f} | \"\n",
    "                  f\"Acc: {val_metrics['accuracy']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "            print(f\"📈 LR: {current_lr:.2e}\")\n",
    "            \n",
    "            # Save best model\n",
    "            is_best = val_metrics['accuracy'] > self.best_val_acc\n",
    "            \n",
    "            if is_best:\n",
    "                self.best_val_acc = val_metrics['accuracy']\n",
    "                self.best_val_f1 = val_metrics['f1']\n",
    "                self.best_epoch = epoch\n",
    "                self.patience_counter = 0\n",
    "                \n",
    "                # Save checkpoint\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                    'best_val_acc': self.best_val_acc,\n",
    "                    'best_val_f1': self.best_val_f1,\n",
    "                    'history': self.history,\n",
    "                }\n",
    "                \n",
    "                torch.save(checkpoint, self.config.MODELS_DIR / 'best_model.pth')\n",
    "                print(f\"💾 Mejor modelo guardado! Val Acc: {self.best_val_acc:.4f}\")\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                print(f\"⏳ Patience: {self.patience_counter}/{self.config.PATIENCE}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.patience_counter >= self.config.PATIENCE:\n",
    "                print(f\"\\n⚠️ Early stopping activado en epoch {epoch+1}\")\n",
    "                print(f\"   Mejor val acc: {self.best_val_acc:.4f} (epoch {self.best_epoch+1})\")\n",
    "                break\n",
    "            \n",
    "            # Save checkpoint every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                checkpoint_path = self.config.MODELS_DIR / f'checkpoint_epoch_{epoch+1}.pth'\n",
    "                torch.save(checkpoint, checkpoint_path)\n",
    "                print(f\"💾 Checkpoint guardado: {checkpoint_path}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"✅ ENTRENAMIENTO COMPLETADO\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Mejor modelo: Epoch {self.best_epoch+1}\")\n",
    "        print(f\"  Val Accuracy: {self.best_val_acc:.4f}\")\n",
    "        print(f\"  Val F1-Score: {self.best_val_f1:.4f}\")\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "\n",
    "def create_optimizer_and_scheduler(model, train_loader, config):\n",
    "    \"\"\"Crea optimizer y scheduler optimizados\"\"\"\n",
    "    \n",
    "    # Separar parámetros para diferentes learning rates\n",
    "    # Backbone: LR más bajo\n",
    "    # Heads: LR más alto\n",
    "    \n",
    "    backbone_params = []\n",
    "    head_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'image_model' in name:\n",
    "            backbone_params.append(param)\n",
    "        else:\n",
    "            head_params.append(param)\n",
    "    \n",
    "    # Optimizer: AdamW con weight decay\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': backbone_params, 'lr': config.LEARNING_RATE * 0.1},  # 10x menor para backbone\n",
    "        {'params': head_params, 'lr': config.LEARNING_RATE}\n",
    "    ], weight_decay=config.WEIGHT_DECAY)\n",
    "    \n",
    "    # Scheduler: Cosine Annealing con Warmup\n",
    "    num_training_steps = len(train_loader) * config.EPOCHS\n",
    "    num_warmup_steps = len(train_loader) * config.WARMUP_EPOCHS\n",
    "    \n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            # Linear warmup\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        # Cosine annealing\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + np.cos(np.pi * progress)))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    # Alternativa: ReduceLROnPlateau\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, mode='min', factor=0.5, patience=5, verbose=True, min_lr=config.MIN_LR\n",
    "    # )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "print(\"✅ Training loop y optimización configurados\")\n",
    "print(\"   - AdamW optimizer con differential learning rates\")\n",
    "print(\"   - Cosine annealing con warmup\")\n",
    "print(\"   - Gradient clipping\")\n",
    "print(\"   - Automatic Mixed Precision (AMP)\")\n",
    "print(\"   - Early stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGNÓSTICO COMPLETO DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Para ver errores exactos\n",
    "\n",
    "print(\"🔍 DIAGNÓSTICO COMPLETO DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Verificar estructura del dataset\n",
    "print(\"\\n📦 Verificando primer batch del train_loader...\")\n",
    "try:\n",
    "    test_batch = next(iter(train_loader))\n",
    "    print(f\"✅ Batch cargado exitosamente\")\n",
    "    print(f\"\\nShapes:\")\n",
    "    print(f\"   Images: {test_batch['image'].shape}\")\n",
    "    print(f\"   Metadata: {test_batch['metadata'].shape}\")\n",
    "    print(f\"   Labels: {test_batch['label'].shape}\")\n",
    "    \n",
    "    # Verificar rangos\n",
    "    print(f\"\\nRangos de valores:\")\n",
    "    print(f\"   Images: [{test_batch['image'].min():.3f}, {test_batch['image'].max():.3f}]\")\n",
    "    print(f\"   Metadata: [{test_batch['metadata'].min():.3f}, {test_batch['metadata'].max():.3f}]\")\n",
    "    print(f\"   Labels: [{test_batch['label'].min()}, {test_batch['label'].max()}]\")\n",
    "    \n",
    "    # CRÍTICO: Verificar que labels están en rango correcto\n",
    "    max_label = test_batch['label'].max().item()\n",
    "    print(f\"\\n🎯 Verificación de labels:\")\n",
    "    print(f\"   Max label en batch: {max_label}\")\n",
    "    print(f\"   Num classes esperado: {num_classes}\")\n",
    "    \n",
    "    if max_label >= num_classes:\n",
    "        print(f\"   ❌ ERROR CRÍTICO: Label {max_label} >= num_classes {num_classes}\")\n",
    "        print(f\"   Las labels deben estar en rango [0, {num_classes-1}]\")\n",
    "    else:\n",
    "        print(f\"   ✅ Labels en rango correcto [0, {num_classes-1}]\")\n",
    "    \n",
    "    # 2. Verificar dimensiones categóricas\n",
    "    print(f\"\\n📊 Verificando categorical dimensions:\")\n",
    "    print(f\"   Total categorical features: {len(preprocessor.categorical_features)}\")\n",
    "    print(f\"   Categorical dims: {preprocessor.categorical_dims}\")\n",
    "    \n",
    "    # 3. Verificar que cat_feature_indices coincide con categorical_dims\n",
    "    print(f\"\\n🔑 Verificando cat_feature_indices:\")\n",
    "    print(f\"   cat_feature_indices keys: {list(cat_feature_indices.keys())}\")\n",
    "    print(f\"   categorical_dims keys: {list(preprocessor.categorical_dims.keys())}\")\n",
    "    \n",
    "    if set(cat_feature_indices.keys()) != set(preprocessor.categorical_dims.keys()):\n",
    "        print(f\"   ❌ ERROR: Las keys no coinciden!\")\n",
    "    else:\n",
    "        print(f\"   ✅ Keys coinciden correctamente\")\n",
    "    \n",
    "    # 4. Verificar valores categóricos en el batch\n",
    "    metadata_batch = test_batch['metadata']\n",
    "    print(f\"\\n📊 Verificando valores categóricos en metadata:\")\n",
    "    \n",
    "    cat_start_idx = 0\n",
    "    for feat_name in preprocessor.categorical_features:\n",
    "        if feat_name in preprocessor.categorical_dims:\n",
    "            max_dim = preprocessor.categorical_dims[feat_name]\n",
    "            col_values = metadata_batch[:, cat_start_idx]\n",
    "            min_val = col_values.min().item()\n",
    "            max_val = col_values.max().item()\n",
    "            \n",
    "            print(f\"   {feat_name}: range=[{min_val:.0f}, {max_val:.0f}], dim={max_dim}\")\n",
    "            \n",
    "            if max_val >= max_dim:\n",
    "                print(f\"      ❌ ERROR: Valor {max_val:.0f} >= dim {max_dim}\")\n",
    "            \n",
    "            cat_start_idx += 1\n",
    "    \n",
    "    # 5. PRUEBA CRÍTICA: Intentar forward pass\n",
    "    print(f\"\\n🧪 PRUEBA DE FORWARD PASS:\")\n",
    "    try:\n",
    "        images = test_batch['image'].to(device)\n",
    "        metadata = test_batch['metadata'].to(device)\n",
    "        labels = test_batch['label'].to(device)\n",
    "        \n",
    "        print(f\"   Datos movidos a GPU...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print(f\"   Intentando forward pass...\")\n",
    "            logits = model(images, metadata, cat_feature_indices)\n",
    "            print(f\"   ✅ Forward pass exitoso!\")\n",
    "            print(f\"   Output shape: {logits.shape}\")\n",
    "            \n",
    "            # Verificar que la salida tiene el número correcto de clases\n",
    "            if logits.shape[1] != num_classes:\n",
    "                print(f\"   ❌ ERROR: Output tiene {logits.shape[1]} clases, esperado {num_classes}\")\n",
    "            else:\n",
    "                print(f\"   ✅ Output correcto: {num_classes} clases\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ ERROR en forward pass:\")\n",
    "        print(f\"   {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    del test_batch\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error cargando batch:\")\n",
    "    print(f\"   {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ Diagnóstico completado\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 9: EJECUTAR ENTRENAMIENTO\n",
    "# ============================================================================\n",
    "\n",
    "# Crear modelo\n",
    "print(\"🏗️ Creando modelo...\")\n",
    "model = create_model(\n",
    "    num_classes=num_classes,\n",
    "    categorical_dims=preprocessor.categorical_dims,\n",
    "    num_numerical_features=len(preprocessor.numerical_features)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Contar parámetros\n",
    "trainable_params, total_params = count_parameters(model)\n",
    "print(f\"\\n📊 Parámetros del modelo:\")\n",
    "print(f\"   Total: {total_params:,}\")\n",
    "print(f\"   Entrenables: {trainable_params:,}\")\n",
    "print(f\"   No entrenables: {total_params - trainable_params:,}\")\n",
    "\n",
    "# Crear loss function\n",
    "criterion = CombinedLoss(\n",
    "    class_weights=class_weights,\n",
    "    focal_gamma=2.0,\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\n🎯 Loss function: Combined (Focal + Label Smoothing)\")\n",
    "\n",
    "# Crear optimizer y scheduler\n",
    "optimizer, scheduler = create_optimizer_and_scheduler(model, train_loader, Config)\n",
    "\n",
    "print(f\"\\n⚙️ Optimizer: AdamW\")\n",
    "print(f\"   Learning rate (backbone): {Config.LEARNING_RATE * 0.1:.2e}\")\n",
    "print(f\"   Learning rate (heads): {Config.LEARNING_RATE:.2e}\")\n",
    "print(f\"   Weight decay: {Config.WEIGHT_DECAY:.2e}\")\n",
    "print(f\"\\n📅 Scheduler: Cosine Annealing con Warmup\")\n",
    "print(f\"   Warmup epochs: {Config.WARMUP_EPOCHS}\")\n",
    "print(f\"   Total epochs: {Config.EPOCHS}\")\n",
    "\n",
    "# Crear trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    cat_indices=cat_feature_indices,\n",
    "    device=device,\n",
    "    config=Config\n",
    ")\n",
    "\n",
    "# ENTRENAR\n",
    "history = trainer.train()\n",
    "\n",
    "# Guardar history\n",
    "with open(Config.OUTPUT_DIR / 'training_history.json', 'w') as f:\n",
    "    # Convertir history a formato serializable\n",
    "    history_serializable = {\n",
    "        k: [float(v) if isinstance(v, (np.floating, float)) else v for v in vals]\n",
    "        for k, vals in history.items()\n",
    "    }\n",
    "    json.dump(history_serializable, f, indent=2)\n",
    "\n",
    "print(\"\\n💾 Training history guardado\")\n",
    "\n",
    "# Visualizar training history\n",
    "plot_training_history(history, save_path=Config.OUTPUT_DIR / 'training_curves.png')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ ENTRENAMIENTO FINALIZADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799de53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 10: EVALUACIÓN CON TEST-TIME AUGMENTATION (TTA)\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_with_tta(model, dataloader, cat_indices, device, tta_transforms=5):\n",
    "    \"\"\"Evalúa el modelo con TTA\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    tta_augmenter = TTATransform(img_size=Config.IMG_SIZE)\n",
    "    \n",
    "    print(f\"🔍 Evaluando con TTA ({tta_transforms} augmentations)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='TTA Evaluation'):\n",
    "            images_orig = batch['image']\n",
    "            metadata = batch['metadata'].to(device)\n",
    "            labels = batch['label']\n",
    "            \n",
    "            batch_size = images_orig.size(0)\n",
    "            tta_probs = []\n",
    "            \n",
    "            # Para cada imagen en el batch\n",
    "            for i in range(batch_size):\n",
    "                img_path = dataloader.dataset.image_paths[i]\n",
    "                img_pil = Image.open(img_path).convert('RGB')\n",
    "                \n",
    "                # Aplicar TTA transforms\n",
    "                tta_images = tta_augmenter(img_pil)\n",
    "                \n",
    "                # Promediar predicciones\n",
    "                img_probs = []\n",
    "                for tta_img in tta_images:\n",
    "                    tta_img_batch = tta_img.unsqueeze(0).to(device)\n",
    "                    meta_batch = metadata[i:i+1]\n",
    "                    \n",
    "                    with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                        logits = model(tta_img_batch, meta_batch, cat_indices)\n",
    "                        probs = F.softmax(logits, dim=1)\n",
    "                    \n",
    "                    img_probs.append(probs.cpu())\n",
    "                \n",
    "                # Promediar probabilidades de todas las augmentations\n",
    "                avg_probs = torch.stack(img_probs).mean(dim=0)\n",
    "                tta_probs.append(avg_probs)\n",
    "            \n",
    "            # Stack batch probabilities\n",
    "            batch_probs = torch.cat(tta_probs, dim=0)\n",
    "            batch_preds = torch.argmax(batch_probs, dim=1)\n",
    "            \n",
    "            all_probs.append(batch_probs)\n",
    "            all_preds.append(batch_preds)\n",
    "            all_targets.append(labels)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_probs = torch.cat(all_probs, dim=0).numpy()\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "    \n",
    "    return all_preds, all_probs, all_targets\n",
    "\n",
    "\n",
    "def evaluate_standard(model, dataloader, cat_indices, device):\n",
    "    \"\"\"Evaluación estándar sin TTA\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(f\"🔍 Evaluando (estándar)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Standard Evaluation'):\n",
    "            images = batch['image'].to(device)\n",
    "            metadata = batch['metadata'].to(device)\n",
    "            labels = batch['label']\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                logits = model(images, metadata, cat_indices)\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "            \n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            all_probs.append(probs.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(labels)\n",
    "    \n",
    "    all_probs = torch.cat(all_probs, dim=0).numpy()\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "    \n",
    "    return all_preds, all_probs, all_targets\n",
    "\n",
    "\n",
    "# Cargar mejor modelo\n",
    "print(\"📥 Cargando mejor modelo...\")\n",
    "checkpoint = torch.load(Config.MODELS_DIR / 'best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"✅ Modelo cargado (Epoch {checkpoint['epoch']+1})\")\n",
    "\n",
    "# ===== EVALUACIÓN EN VALIDATION SET =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 EVALUACIÓN EN VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sin TTA\n",
    "val_preds, val_probs, val_targets = evaluate_standard(model, val_loader, cat_feature_indices, device)\n",
    "\n",
    "val_acc = accuracy_score(val_targets, val_preds)\n",
    "val_f1_weighted = f1_score(val_targets, val_preds, average='weighted')\n",
    "val_f1_macro = f1_score(val_targets, val_preds, average='macro')\n",
    "\n",
    "print(f\"\\n📈 Resultados (Sin TTA):\")\n",
    "print(f\"   Accuracy: {val_acc:.4f}\")\n",
    "print(f\"   F1-Score (weighted): {val_f1_weighted:.4f}\")\n",
    "print(f\"   F1-Score (macro): {val_f1_macro:.4f}\")\n",
    "\n",
    "# Con TTA\n",
    "val_preds_tta, val_probs_tta, val_targets_tta = evaluate_with_tta(\n",
    "    model, val_loader, cat_feature_indices, device, tta_transforms=Config.TTA_TRANSFORMS\n",
    ")\n",
    "\n",
    "val_acc_tta = accuracy_score(val_targets_tta, val_preds_tta)\n",
    "val_f1_weighted_tta = f1_score(val_targets_tta, val_preds_tta, average='weighted')\n",
    "val_f1_macro_tta = f1_score(val_targets_tta, val_preds_tta, average='macro')\n",
    "\n",
    "print(f\"\\n📈 Resultados (Con TTA):\")\n",
    "print(f\"   Accuracy: {val_acc_tta:.4f} ({'+' if val_acc_tta > val_acc else ''}{val_acc_tta - val_acc:+.4f})\")\n",
    "print(f\"   F1-Score (weighted): {val_f1_weighted_tta:.4f} ({'+' if val_f1_weighted_tta > val_f1_weighted else ''}{val_f1_weighted_tta - val_f1_weighted:+.4f})\")\n",
    "print(f\"   F1-Score (macro): {val_f1_macro_tta:.4f} ({'+' if val_f1_macro_tta > val_f1_macro else ''}{val_f1_macro_tta - val_f1_macro:+.4f})\")\n",
    "\n",
    "# Matriz de confusión\n",
    "cm_val = confusion_matrix(val_targets_tta, val_preds_tta)\n",
    "plot_confusion_matrix(cm_val, class_names, save_path=Config.OUTPUT_DIR / 'confusion_matrix_val.png')\n",
    "\n",
    "# ===== EVALUACIÓN EN TEST SET =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 EVALUACIÓN FINAL EN TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sin TTA\n",
    "test_preds, test_probs, test_targets = evaluate_standard(model, test_loader, cat_feature_indices, device)\n",
    "\n",
    "test_acc = accuracy_score(test_targets, test_preds)\n",
    "test_f1_weighted = f1_score(test_targets, test_preds, average='weighted')\n",
    "test_f1_macro = f1_score(test_targets, test_preds, average='macro')\n",
    "\n",
    "print(f\"\\n📈 Resultados (Sin TTA):\")\n",
    "print(f\"   Accuracy: {test_acc:.4f}\")\n",
    "print(f\"   F1-Score (weighted): {test_f1_weighted:.4f}\")\n",
    "print(f\"   F1-Score (macro): {test_f1_macro:.4f}\")\n",
    "\n",
    "# Con TTA\n",
    "test_preds_tta, test_probs_tta, test_targets_tta = evaluate_with_tta(\n",
    "    model, test_loader, cat_feature_indices, device, tta_transforms=Config.TTA_TRANSFORMS\n",
    ")\n",
    "\n",
    "test_acc_tta = accuracy_score(test_targets_tta, test_preds_tta)\n",
    "test_f1_weighted_tta = f1_score(test_targets_tta, test_preds_tta, average='weighted')\n",
    "test_f1_macro_tta = f1_score(test_targets_tta, test_preds_tta, average='macro')\n",
    "test_precision_tta = precision_score(test_targets_tta, test_preds_tta, average='weighted')\n",
    "test_recall_tta = recall_score(test_targets_tta, test_preds_tta, average='weighted')\n",
    "\n",
    "print(f\"\\n📈 Resultados (Con TTA):\")\n",
    "print(f\"   Accuracy: {test_acc_tta:.4f} ({'+' if test_acc_tta > test_acc else ''}{test_acc_tta - test_acc:+.4f})\")\n",
    "print(f\"   Precision (weighted): {test_precision_tta:.4f}\")\n",
    "print(f\"   Recall (weighted): {test_recall_tta:.4f}\")\n",
    "print(f\"   F1-Score (weighted): {test_f1_weighted_tta:.4f} ({'+' if test_f1_weighted_tta > test_f1_weighted else ''}{test_f1_weighted_tta - test_f1_weighted:+.4f})\")\n",
    "print(f\"   F1-Score (macro): {test_f1_macro_tta:.4f} ({'+' if test_f1_macro_tta > test_f1_macro else ''}{test_f1_macro_tta - test_f1_macro:+.4f})\")\n",
    "\n",
    "# Classification report detallado\n",
    "print(f\"\\n📋 Classification Report:\")\n",
    "print(classification_report(test_targets_tta, test_preds_tta, target_names=class_names))\n",
    "\n",
    "# Matriz de confusión\n",
    "cm_test = confusion_matrix(test_targets_tta, test_preds_tta)\n",
    "plot_confusion_matrix(cm_test, class_names, save_path=Config.OUTPUT_DIR / 'confusion_matrix_test.png')\n",
    "\n",
    "# Guardar resultados\n",
    "test_results = {\n",
    "    'test_accuracy': float(test_acc_tta),\n",
    "    'test_accuracy_no_tta': float(test_acc),\n",
    "    'test_precision': float(test_precision_tta),\n",
    "    'test_recall': float(test_recall_tta),\n",
    "    'test_f1_weighted': float(test_f1_weighted_tta),\n",
    "    'test_f1_macro': float(test_f1_macro_tta),\n",
    "    'per_class_metrics': {},\n",
    "    'confusion_matrix': cm_test.tolist()\n",
    "}\n",
    "\n",
    "# Per-class metrics\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = test_targets_tta == i\n",
    "    class_preds = test_preds_tta[class_mask]\n",
    "    class_targets = test_targets_tta[class_mask]\n",
    "    \n",
    "    if len(class_targets) > 0:\n",
    "        class_acc = accuracy_score(class_targets, class_preds)\n",
    "        test_results['per_class_metrics'][class_name] = {\n",
    "            'accuracy': float(class_acc),\n",
    "            'samples': int(len(class_targets))\n",
    "        }\n",
    "\n",
    "with open(Config.OUTPUT_DIR / 'test_results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(\"\\n💾 Resultados de test guardados\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ EVALUACIÓN COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n🎯 RESULTADO FINAL:\")\n",
    "print(f\"   Test Accuracy (con TTA): {test_acc_tta:.4f} ({test_acc_tta*100:.2f}%)\")\n",
    "print(f\"   Test F1-Score (weighted): {test_f1_weighted_tta:.4f}\")\n",
    "print(f\"   Mejora con TTA: +{(test_acc_tta - test_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 11: INFERENCIA Y PREDICCIÓN EN NUEVAS IMÁGENES\n",
    "# ============================================================================\n",
    "\n",
    "class SkinCancerPredictor:\n",
    "    \"\"\"Predictor para nuevas imágenes\"\"\"\n",
    "    \n",
    "    def __init__(self, model, preprocessor, cat_indices, class_names, device, use_tta=True):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.cat_indices = cat_indices\n",
    "        self.class_names = class_names\n",
    "        self.device = device\n",
    "        self.use_tta = use_tta\n",
    "        \n",
    "        self.transform = AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='val')\n",
    "        self.tta_transform = TTATransform(img_size=Config.IMG_SIZE) if use_tta else None\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict_single(self, image_path, metadata_dict):\n",
    "        \"\"\"\n",
    "        Predice una sola imagen\n",
    "        \n",
    "        Args:\n",
    "            image_path: ruta a la imagen\n",
    "            metadata_dict: diccionario con metadatos (mismo formato que CSV)\n",
    "        \n",
    "        Returns:\n",
    "            dict con predicción, probabilidades y confianza\n",
    "        \"\"\"\n",
    "        # Preprocesar metadata\n",
    "        metadata_df = pd.DataFrame([metadata_dict])\n",
    "        metadata_processed, _ = self.preprocessor.transform(metadata_df)\n",
    "        metadata_tensor = torch.FloatTensor(metadata_processed).to(self.device)\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.use_tta and self.tta_transform is not None:\n",
    "                # TTA\n",
    "                tta_images = self.tta_transform(image)\n",
    "                tta_probs = []\n",
    "                \n",
    "                for tta_img in tta_images:\n",
    "                    tta_img_batch = tta_img.unsqueeze(0).to(self.device)\n",
    "                    \n",
    "                    with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                        logits = self.model(tta_img_batch, metadata_tensor, self.cat_indices)\n",
    "                        probs = F.softmax(logits, dim=1)\n",
    "                    \n",
    "                    tta_probs.append(probs.cpu())\n",
    "                \n",
    "                # Promediar probabilidades\n",
    "                avg_probs = torch.stack(tta_probs).mean(dim=0)\n",
    "            else:\n",
    "                # Predicción estándar\n",
    "                img_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                    logits = self.model(img_tensor, metadata_tensor, self.cat_indices)\n",
    "                    avg_probs = F.softmax(logits, dim=1).cpu()\n",
    "        \n",
    "        # Obtener predicción\n",
    "        pred_class_idx = torch.argmax(avg_probs, dim=1).item()\n",
    "        pred_class_name = self.class_names[pred_class_idx]\n",
    "        confidence = avg_probs[0, pred_class_idx].item()\n",
    "        \n",
    "        # Todas las probabilidades\n",
    "        class_probs = {\n",
    "            name: float(avg_probs[0, i].item())\n",
    "            for i, name in enumerate(self.class_names)\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'predicted_class': pred_class_name,\n",
    "            'predicted_class_idx': pred_class_idx,\n",
    "            'confidence': confidence,\n",
    "            'class_probabilities': class_probs,\n",
    "            'top_3_predictions': sorted(\n",
    "                class_probs.items(),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )[:3]\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict_batch(self, image_paths, metadata_dicts):\n",
    "        \"\"\"Predice múltiples imágenes\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for img_path, meta_dict in tqdm(zip(image_paths, metadata_dicts), \n",
    "                                        total=len(image_paths),\n",
    "                                        desc='Prediciendo'):\n",
    "            result = self.predict_single(img_path, meta_dict)\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_prediction(self, image_path, metadata_dict, save_path=None):\n",
    "        \"\"\"Visualiza predicción con probabilidades\"\"\"\n",
    "        result = self.predict_single(image_path, metadata_dict)\n",
    "        \n",
    "        # Crear figura\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Mostrar imagen\n",
    "        img = Image.open(image_path)\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].axis('off')\n",
    "        axes[0].set_title(f'Predicción: {result[\"predicted_class\"]}\\n'\n",
    "                         f'Confianza: {result[\"confidence\"]:.2%}',\n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Mostrar probabilidades\n",
    "        probs = result['class_probabilities']\n",
    "        classes = list(probs.keys())\n",
    "        values = list(probs.values())\n",
    "        \n",
    "        colors = ['green' if c == result['predicted_class'] else 'steelblue' \n",
    "                 for c in classes]\n",
    "        \n",
    "        axes[1].barh(classes, values, color=colors)\n",
    "        axes[1].set_xlabel('Probabilidad', fontsize=12)\n",
    "        axes[1].set_title('Probabilidades por Clase', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlim(0, 1)\n",
    "        \n",
    "        for i, (c, v) in enumerate(zip(classes, values)):\n",
    "            axes[1].text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Imprimir resultado detallado\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PREDICCIÓN DETALLADA\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Clase predicha: {result['predicted_class']}\")\n",
    "        print(f\"Confianza: {result['confidence']:.2%}\")\n",
    "        print(f\"\\nTop 3 predicciones:\")\n",
    "        for i, (cls, prob) in enumerate(result['top_3_predictions'], 1):\n",
    "            print(f\"  {i}. {cls}: {prob:.2%}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# Crear predictor\n",
    "print(\"🔮 Creando predictor...\")\n",
    "predictor = SkinCancerPredictor(\n",
    "    model=model,\n",
    "    preprocessor=preprocessor,\n",
    "    cat_indices=cat_feature_indices,\n",
    "    class_names=class_names,\n",
    "    device=device,\n",
    "    use_tta=True\n",
    ")\n",
    "\n",
    "print(\"✅ Predictor listo\")\n",
    "\n",
    "# ===== EJEMPLO DE USO =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EJEMPLO DE PREDICCIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Tomar una muestra del test set\n",
    "sample_idx = 0\n",
    "sample_img_path = test_dataset.image_paths[sample_idx]\n",
    "sample_metadata = df_processed.iloc[X_test[sample_idx]].to_dict()\n",
    "sample_true_label = class_names[test_dataset.labels[sample_idx].item()]\n",
    "\n",
    "print(f\"\\nImagen de ejemplo: {sample_img_path}\")\n",
    "print(f\"Diagnóstico real: {sample_true_label}\")\n",
    "\n",
    "# Predecir\n",
    "predictor.visualize_prediction(\n",
    "    sample_img_path,\n",
    "    sample_metadata,\n",
    "    save_path=Config.OUTPUT_DIR / 'example_prediction.png'\n",
    ")\n",
    "\n",
    "# ===== FUNCIÓN PARA PREDICCIÓN DE NUEVAS IMÁGENES =====\n",
    "def predict_new_image(image_path, metadata_dict=None):\n",
    "    \"\"\"\n",
    "    Función helper para predecir nuevas imágenes\n",
    "    \n",
    "    Args:\n",
    "        image_path: ruta a la imagen\n",
    "        metadata_dict: diccionario con metadatos (opcional, se usarán valores por defecto)\n",
    "    \n",
    "    Ejemplo:\n",
    "        metadata = {\n",
    "            'age': 45,\n",
    "            'gender': 'FEMALE',\n",
    "            'region': 'ARM',\n",
    "            'diameter_1': 5.0,\n",
    "            'diameter_2': 4.0,\n",
    "            'smoke': False,\n",
    "            'drink': False,\n",
    "            # ... más campos\n",
    "        }\n",
    "        result = predict_new_image('path/to/image.png', metadata)\n",
    "    \"\"\"\n",
    "    if metadata_dict is None:\n",
    "        # Valores por defecto\n",
    "        metadata_dict = {\n",
    "            'age': 50,\n",
    "            'gender': 'UNKNOWN',\n",
    "            'region': 'UNKNOWN',\n",
    "            'smoke': 'UNKNOWN',\n",
    "            'drink': 'UNKNOWN',\n",
    "            'background_father': 'UNKNOWN',\n",
    "            'background_mother': 'UNKNOWN',\n",
    "            'pesticide': 'UNKNOWN',\n",
    "            'skin_cancer_history': 'UNKNOWN',\n",
    "            'cancer_history': 'UNKNOWN',\n",
    "            'has_piped_water': 'UNKNOWN',\n",
    "            'has_sewage_system': 'UNKNOWN',\n",
    "            'fitspatrick': 3.0,\n",
    "            'diameter_1': 5.0,\n",
    "            'diameter_2': 5.0,\n",
    "            'itch': False,\n",
    "            'grew': False,\n",
    "            'hurt': False,\n",
    "            'changed': False,\n",
    "            'bleed': False,\n",
    "            'elevation': False,\n",
    "            'biopsed': False\n",
    "        }\n",
    "    \n",
    "    result = predictor.predict_single(image_path, metadata_dict)\n",
    "    \n",
    "    # Visualizar\n",
    "    predictor.visualize_prediction(\n",
    "        image_path,\n",
    "        metadata_dict,\n",
    "        save_path=Config.OUTPUT_DIR / f'prediction_{Path(image_path).stem}.png'\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✅ SISTEMA DE PREDICCIÓN LISTO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nPara predecir nuevas imágenes, usa:\")\n",
    "print(\"  result = predict_new_image('path/to/image.png', metadata_dict)\")\n",
    "print(\"\\nDonde metadata_dict es un diccionario con los campos del CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 12: RESUMEN Y ANÁLISIS FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*20 + \"🏆 RESUMEN DEL MODELO 🏆\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "📊 ARQUITECTURA:\n",
    "   • Modelo de imagen: {Config.EFFICIENTNET_MODEL}\n",
    "   • Tamaño de entrada: {Config.IMG_SIZE}x{Config.IMG_SIZE}\n",
    "   • TabTransformer: {Config.TAB_NUM_LAYERS} layers, {Config.TAB_NUM_HEADS} heads\n",
    "   • Fusión: Late fusion con MLP ({' -> '.join(map(str, Config.FUSION_HIDDEN_DIMS))})\n",
    "   • Parámetros totales: {total_params:,}\n",
    "   • Parámetros entrenables: {trainable_params:,}\n",
    "\n",
    "🎯 TÉCNICAS APLICADAS:\n",
    "   ✓ EfficientNetV2-M pre-entrenado\n",
    "   ✓ TabTransformer para metadatos tabulares\n",
    "   ✓ Late Fusion multimodal\n",
    "   ✓ Augmentations avanzadas (geométricas, colorimétricas, ópticas)\n",
    "   ✓ Mixup & CutMix durante entrenamiento\n",
    "   ✓ Combined Loss (Focal + Label Smoothing)\n",
    "   ✓ Class weighting para desbalanceo\n",
    "   ✓ Differential learning rates (backbone vs heads)\n",
    "   ✓ Cosine Annealing con Warmup\n",
    "   ✓ Gradient clipping\n",
    "   ✓ Automatic Mixed Precision (AMP)\n",
    "   ✓ Early stopping\n",
    "   ✓ Test-Time Augmentation (TTA)\n",
    "   \n",
    "📈 RESULTADOS:\n",
    "   • Val Accuracy: {checkpoint['best_val_acc']:.4f} ({checkpoint['best_val_acc']*100:.2f}%)\n",
    "   • Test Accuracy (sin TTA): {test_acc:.4f} ({test_acc*100:.2f}%)\n",
    "   • Test Accuracy (con TTA): {test_acc_tta:.4f} ({test_acc_tta*100:.2f}%)\n",
    "   • Test F1-Score: {test_f1_weighted_tta:.4f}\n",
    "   • Mejora con TTA: +{(test_acc_tta - test_acc)*100:.2f}%\n",
    "   \n",
    "💾 ARCHIVOS GENERADOS:\n",
    "   • {Config.MODELS_DIR / 'best_model.pth'}\n",
    "   • {Config.OUTPUT_DIR / 'metadata_preprocessor.pkl'}\n",
    "   • {Config.OUTPUT_DIR / 'training_history.json'}\n",
    "   • {Config.OUTPUT_DIR / 'test_results.json'}\n",
    "   • {Config.OUTPUT_DIR / 'training_curves.png'}\n",
    "   • {Config.OUTPUT_DIR / 'confusion_matrix_test.png'}\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*15 + \"🚀 TÉCNICAS PARA MEJORAR RENDIMIENTO 🚀\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "Si quieres mejorar aún más el modelo (objetivo: 98%+), considera:\n",
    "\n",
    "1. 📸 DATOS Y AUGMENTATION:\n",
    "   • Aumentar resolución a 640px (requiere más GPU memory)\n",
    "   • Agregar más augmentations específicas para dermatología:\n",
    "     - Simulación de diferentes iluminaciones (dermoscopia)\n",
    "     - Simulación de vello (hair occlusion)\n",
    "     - Ajustes de contraste específicos para lesiones\n",
    "   • Recolectar más datos (especialmente de clases minoritarias)\n",
    "   • Usar pseudo-labeling con datos no etiquetados\n",
    "\n",
    "2. 🏗️ ARQUITECTURA:\n",
    "   • Ensembling de múltiples modelos:\n",
    "     - EfficientNetV2-L + ConvNeXt + Swin Transformer\n",
    "   • Attention mechanisms más sofisticados:\n",
    "     - CBAM (Convolutional Block Attention Module)\n",
    "     - Squeeze-and-Excitation\n",
    "   • Cross-attention entre imagen y metadatos\n",
    "\n",
    "3. 🎓 ENTRENAMIENTO:\n",
    "   • Progressive resizing (empezar con 224px, luego 384px, finalmente 512px)\n",
    "   • Two-stage training:\n",
    "     - Stage 1: Solo clasificación básica\n",
    "     - Stage 2: Fine-tuning con metadatos\n",
    "   • Knowledge distillation de modelos grandes\n",
    "   • Self-supervised pre-training en datos de dermatología\n",
    "\n",
    "4. 🔧 OPTIMIZACIÓN:\n",
    "   • Usar SAM optimizer (Sharpness-Aware Minimization)\n",
    "   • Stochastic Weight Averaging (SWA)\n",
    "   • Gradient accumulation para batches más grandes\n",
    "   • FP16/BF16 training completo\n",
    "\n",
    "5. 📊 POST-PROCESSING:\n",
    "   • Calibración de probabilidades (Temperature Scaling, Platt Scaling)\n",
    "   • Threshold optimization por clase\n",
    "   • Ensembling con diferentes seeds\n",
    "   • TTA más agresivo (más transformaciones)\n",
    "\n",
    "6. 🔍 ANÁLISIS DE ERRORES:\n",
    "   • Identificar clases confusas y aplicar técnicas específicas\n",
    "   • Análisis de muestras mal clasificadas\n",
    "   • Feature importance analysis\n",
    "   • GradCAM para interpretabilidad\n",
    "\n",
    "7. 🎯 TÉCNICAS ESPECÍFICAS PARA DESBALANCEO:\n",
    "   • Focal Loss con diferentes gammas por clase\n",
    "   • Class-balanced Loss\n",
    "   • Oversampling más agresivo con ADASYN\n",
    "   • Crear muestras sintéticas con GANs\n",
    "\n",
    "8. 💡 METADATA ENGINEERING:\n",
    "   • Extraer features automáticas de las imágenes:\n",
    "     - Descriptores de color (histogramas HSV)\n",
    "     - Textura (Haralick features, LBP)\n",
    "     - Forma (momentos de Hu, contornos)\n",
    "   • Combinar con metadatos clínicos\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*25 + \"📝 CÓDIGO DE EJEMPLO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "# EJEMPLO 1: Entrenar con resolución más alta\n",
    "Config.IMG_SIZE = 640\n",
    "Config.BATCH_SIZE = 8  # Reducir batch size\n",
    "\n",
    "# EJEMPLO 2: Ensembling de modelos\n",
    "models = [\n",
    "    create_model(..., img_model_name='tf_efficientnetv2_l'),\n",
    "    create_model(..., img_model_name='convnext_base'),\n",
    "    create_model(..., img_model_name='swin_base_patch4_window7_224')\n",
    "]\n",
    "\n",
    "def ensemble_predict(models, image, metadata):\n",
    "    probs = []\n",
    "    for model in models:\n",
    "        logits = model(image, metadata, cat_indices)\n",
    "        prob = F.softmax(logits, dim=1)\n",
    "        probs.append(prob)\n",
    "    return torch.stack(probs).mean(dim=0)\n",
    "\n",
    "# EJEMPLO 3: Progressive resizing\n",
    "# Stage 1: 224px, 30 epochs\n",
    "# Stage 2: 384px, 20 epochs  \n",
    "# Stage 3: 512px, 20 epochs\n",
    "\n",
    "# EJEMPLO 4: Pseudo-labeling\n",
    "# 1. Entrenar modelo inicial\n",
    "# 2. Predecir en datos no etiquetados con alta confianza\n",
    "# 3. Agregar predicciones confiables al training set\n",
    "# 4. Re-entrenar\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*20 + \"✅ SISTEMA COMPLETO Y LISTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar resumen final\n",
    "summary = {\n",
    "    'model_config': {\n",
    "        'image_model': Config.EFFICIENTNET_MODEL,\n",
    "        'img_size': Config.IMG_SIZE,\n",
    "        'batch_size': Config.BATCH_SIZE,\n",
    "        'epochs_trained': checkpoint['epoch'] + 1,\n",
    "    },\n",
    "    'results': {\n",
    "        'best_val_acc': float(checkpoint['best_val_acc']),\n",
    "        'best_val_f1': float(checkpoint['best_val_f1']),\n",
    "        'test_acc_no_tta': float(test_acc),\n",
    "        'test_acc_tta': float(test_acc_tta),\n",
    "        'test_f1_weighted': float(test_f1_weighted_tta),\n",
    "        'test_f1_macro': float(test_f1_macro_tta),\n",
    "        'tta_improvement': float((test_acc_tta - test_acc) * 100)\n",
    "    },\n",
    "    'techniques': [\n",
    "        'EfficientNetV2-M pre-trained',\n",
    "        'TabTransformer for metadata',\n",
    "        'Late Fusion',\n",
    "        'Advanced Augmentations',\n",
    "        'Mixup & CutMix',\n",
    "        'Combined Loss (Focal + Label Smoothing)',\n",
    "        'Class Weighting',\n",
    "        'Differential Learning Rates',\n",
    "        'Cosine Annealing with Warmup',\n",
    "        'Gradient Clipping',\n",
    "        'Automatic Mixed Precision',\n",
    "        'Early Stopping',\n",
    "        'Test-Time Augmentation'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(Config.OUTPUT_DIR / 'final_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n💾 Resumen final guardado en: {Config.OUTPUT_DIR / 'final_summary.json'}\")\n",
    "print(f\"\\n🎉 ¡Entrenamiento completado con éxito!\")\n",
    "print(f\"   Accuracy final: {test_acc_tta*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec542bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
