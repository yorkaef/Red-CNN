{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 1: IMPORTS Y CONFIGURACI√ìN INICIAL\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import functional as TF\n",
    "import torchvision.models as models\n",
    "\n",
    "# Timm para modelos\n",
    "import timm\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Imbalanced-learn para SMOTE\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Albumentations para augmentations avanzadas\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# PIL\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n de dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Usando dispositivo: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memoria disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "# Configuraci√≥n general\n",
    "class Config:\n",
    "    # Rutas\n",
    "    BASE_DIR = Path('skin-cancer-local')\n",
    "    IMAGE_DIRS = [\n",
    "        BASE_DIR / 'images' / 'imgs_part_1',\n",
    "        BASE_DIR / 'images' / 'imgs_part_2',\n",
    "        BASE_DIR / 'images' / 'imgs_part_3'\n",
    "    ]\n",
    "    METADATA_PATH = BASE_DIR / 'metadata.csv'\n",
    "    OUTPUT_DIR = Path('outputs')\n",
    "    MODELS_DIR = OUTPUT_DIR / 'models'\n",
    "    LOGS_DIR = OUTPUT_DIR / 'logs'\n",
    "    \n",
    "    # Par√°metros de imagen\n",
    "    IMG_SIZE = 128  # Resoluci√≥n alta para EfficientNetV2\n",
    "    IMG_MEAN = [0.485, 0.456, 0.406]\n",
    "    IMG_STD = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    # Arquitectura\n",
    "    EFFICIENTNET_MODEL = 'tf_efficientnetv2_m'  # Modelo M para mejor performance\n",
    "    USE_PRETRAINED = True\n",
    "    DROP_PATH_RATE = 0.2\n",
    "    DROP_RATE = 0.3\n",
    "    \n",
    "    # TabTransformer\n",
    "    TAB_EMBED_DIM = 128\n",
    "    TAB_NUM_HEADS = 8\n",
    "    TAB_NUM_LAYERS = 6\n",
    "    TAB_DROPOUT = 0.3\n",
    "    \n",
    "    # Fusi√≥n\n",
    "    FUSION_HIDDEN_DIMS = [512, 256, 128]\n",
    "    FUSION_DROPOUT = 0.4\n",
    "    \n",
    "    # Entrenamiento\n",
    "    BATCH_SIZE = 16  # Ajustar seg√∫n GPU\n",
    "    EPOCHS = 100\n",
    "    LEARNING_RATE = 1e-4\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    WARMUP_EPOCHS = 5\n",
    "    PATIENCE = 15\n",
    "    MIN_LR = 1e-7\n",
    "    \n",
    "    # Cross-validation\n",
    "    N_FOLDS = 5\n",
    "    \n",
    "    # Augmentation\n",
    "    MIXUP_ALPHA = 0.4\n",
    "    CUTMIX_ALPHA = 1.0\n",
    "    MIXUP_PROB = 0.5\n",
    "    \n",
    "    # TTA\n",
    "    TTA_TRANSFORMS = 5\n",
    "    \n",
    "    # Random seed\n",
    "    SEED = 42\n",
    "    \n",
    "    # Otros\n",
    "    NUM_WORKERS = 1\n",
    "    PIN_MEMORY = True\n",
    "    AMP_ENABLED = True  # Automatic Mixed Precision\n",
    "\n",
    "# Crear directorios\n",
    "Config.OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "Config.MODELS_DIR.mkdir(exist_ok=True)\n",
    "Config.LOGS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Set seeds para reproducibilidad\n",
    "def set_seed(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(Config.SEED)\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n completada\")\n",
    "print(f\"   Tama√±o de imagen: {Config.IMG_SIZE}x{Config.IMG_SIZE}\")\n",
    "print(f\"   Modelo: {Config.EFFICIENTNET_MODEL}\")\n",
    "print(f\"   Batch size: {Config.BATCH_SIZE}\")\n",
    "print(f\"   √âpocas: {Config.EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ef0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 2: CARGA Y AN√ÅLISIS EXPLORATORIO DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "# Cargar metadata\n",
    "df = pd.read_csv(Config.METADATA_PATH)\n",
    "print(f\"üìä Dataset cargado: {len(df)} muestras\")\n",
    "print(f\"   Columnas: {df.shape[1]}\")\n",
    "\n",
    "# An√°lisis inicial\n",
    "print(\"\\nüìã Primeras filas:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nüîç Informaci√≥n del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nüìà Estad√≠sticas descriptivas:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Verificar im√°genes existentes\n",
    "def find_image_path(img_id):\n",
    "    \"\"\"Busca la imagen en los directorios\"\"\"\n",
    "    for img_dir in Config.IMAGE_DIRS:\n",
    "        img_path = img_dir / img_id\n",
    "        if img_path.exists():\n",
    "            return str(img_path)\n",
    "    return None\n",
    "\n",
    "print(\"\\nüñºÔ∏è Verificando im√°genes...\")\n",
    "df['image_path'] = df['img_id'].apply(find_image_path)\n",
    "missing_images = df['image_path'].isna().sum()\n",
    "print(f\"   Im√°genes encontradas: {len(df) - missing_images}/{len(df)}\")\n",
    "if missing_images > 0:\n",
    "    print(f\"   ‚ö†Ô∏è Im√°genes faltantes: {missing_images}\")\n",
    "    df = df.dropna(subset=['image_path'])\n",
    "\n",
    "# An√°lisis de la variable objetivo\n",
    "print(\"\\nüéØ Distribuci√≥n de diagn√≥sticos:\")\n",
    "diagnostic_counts = df['diagnostic'].value_counts()\n",
    "print(diagnostic_counts)\n",
    "print(f\"\\n   Clases √∫nicas: {df['diagnostic'].nunique()}\")\n",
    "print(f\"   Desbalanceo m√°ximo: {diagnostic_counts.max() / diagnostic_counts.min():.2f}x\")\n",
    "\n",
    "# Visualizaci√≥n de distribuci√≥n\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "diagnostic_counts.plot(kind='bar', color='steelblue')\n",
    "plt.title('Distribuci√≥n de Diagn√≥sticos', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Diagn√≥stico')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(diagnostic_counts.values, labels=diagnostic_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Proporci√≥n de Clases', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.OUTPUT_DIR / 'class_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de variables categ√≥ricas\n",
    "categorical_cols = ['smoke', 'drink', 'gender', 'background_father', 'background_mother',\n",
    "                   'skin_cancer_history', 'cancer_history', 'has_piped_water', \n",
    "                   'has_sewage_system', 'region', 'itch', 'grew', 'hurt', \n",
    "                   'changed', 'bleed', 'elevation', 'biopsed']\n",
    "\n",
    "print(\"\\nüìä Valores √∫nicos en variables categ√≥ricas:\")\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        unique_vals = df[col].nunique()\n",
    "        missing = df[col].isna().sum()\n",
    "        print(f\"   {col}: {unique_vals} valores √∫nicos, {missing} missing ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# An√°lisis de variables num√©ricas\n",
    "numerical_cols = ['age', 'diameter_1', 'diameter_2', 'fitspatrick']\n",
    "\n",
    "print(\"\\nüìä Estad√≠sticas de variables num√©ricas:\")\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n   {col}:\")\n",
    "        print(f\"      Media: {df[col].mean():.2f}\")\n",
    "        print(f\"      Mediana: {df[col].median():.2f}\")\n",
    "        print(f\"      Std: {df[col].std():.2f}\")\n",
    "        print(f\"      Missing: {df[col].isna().sum()} ({df[col].isna().sum()/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Correlaci√≥n con diagn√≥stico\n",
    "print(\"\\nüîó An√°lisis de correlaciones con diagn√≥stico:\")\n",
    "df_encoded = df.copy()\n",
    "le_diag = LabelEncoder()\n",
    "df_encoded['diagnostic_encoded'] = le_diag.fit_transform(df['diagnostic'])\n",
    "\n",
    "for col in numerical_cols:\n",
    "    if col in df.columns and df[col].notna().sum() > 0:\n",
    "        corr = df_encoded[[col, 'diagnostic_encoded']].corr().iloc[0, 1]\n",
    "        print(f\"   {col}: {corr:.3f}\")\n",
    "\n",
    "# Guardar informaci√≥n procesada\n",
    "print(f\"\\nüíæ Dataset final: {len(df)} muestras con im√°genes v√°lidas\")\n",
    "df.to_csv(Config.OUTPUT_DIR / 'processed_metadata.csv', index=False)\n",
    "print(\"‚úÖ An√°lisis exploratorio completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf351c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 3: PREPROCESAMIENTO AVANZADO DE METADATOS\n",
    "# ============================================================================\n",
    "\n",
    "class MetadataPreprocessor:\n",
    "    \"\"\"Preprocesador avanzado para metadatos tabulares\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_names = []\n",
    "        self.categorical_features = []\n",
    "        self.numerical_features = []\n",
    "        self.categorical_dims = {}  # Dimensiones para embedding\n",
    "        \n",
    "    def fit_transform(self, df):\n",
    "        \"\"\"Ajusta y transforma los metadatos\"\"\"\n",
    "        df = df.copy()\n",
    "        processed_features = []\n",
    "        \n",
    "        # 1. VARIABLES CATEG√ìRICAS\n",
    "        categorical_cols = [\n",
    "            'smoke', 'drink', 'gender', 'background_father', 'background_mother',\n",
    "            'pesticide', 'skin_cancer_history', 'cancer_history', \n",
    "            'has_piped_water', 'has_sewage_system', 'region',\n",
    "            'itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation', 'biopsed'\n",
    "        ]\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "                \n",
    "            # Manejar missing values\n",
    "            df[col] = df[col].fillna('UNKNOWN')\n",
    "            \n",
    "            # Convertir booleanos\n",
    "            if df[col].dtype == 'bool':\n",
    "                df[col] = df[col].astype(str)\n",
    "            \n",
    "            # Label encoding\n",
    "            le = LabelEncoder()\n",
    "            df[f'{col}_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "            \n",
    "            self.label_encoders[col] = le\n",
    "            self.categorical_features.append(f'{col}_encoded')\n",
    "            self.categorical_dims[f'{col}_encoded'] = len(le.classes_)\n",
    "            processed_features.append(f'{col}_encoded')\n",
    "        \n",
    "        # 2. VARIABLES NUM√âRICAS\n",
    "        numerical_cols = ['age', 'diameter_1', 'diameter_2', 'fitspatrick']\n",
    "        \n",
    "        for col in numerical_cols:\n",
    "            if col not in df.columns:\n",
    "                continue\n",
    "            \n",
    "            # Imputaci√≥n con mediana\n",
    "            median_val = df[col].median()\n",
    "            df[col] = df[col].fillna(median_val)\n",
    "            \n",
    "            # Escalado robusto (mejor para outliers)\n",
    "            scaler = RobustScaler()\n",
    "            df[f'{col}_scaled'] = scaler.fit_transform(df[[col]])\n",
    "            \n",
    "            self.scalers[col] = scaler\n",
    "            self.numerical_features.append(f'{col}_scaled')\n",
    "            processed_features.append(f'{col}_scaled')\n",
    "        \n",
    "        # 3. FEATURE ENGINEERING\n",
    "        # Ratio de di√°metros (si ambos existen)\n",
    "        if 'diameter_1' in df.columns and 'diameter_2' in df.columns:\n",
    "            df['diameter_ratio'] = df['diameter_1'] / (df['diameter_2'] + 1e-6)\n",
    "            df['diameter_ratio'] = df['diameter_ratio'].fillna(1.0)\n",
    "            \n",
    "            scaler_ratio = RobustScaler()\n",
    "            df['diameter_ratio_scaled'] = scaler_ratio.fit_transform(df[['diameter_ratio']])\n",
    "            \n",
    "            self.scalers['diameter_ratio'] = scaler_ratio\n",
    "            self.numerical_features.append('diameter_ratio_scaled')\n",
    "            processed_features.append('diameter_ratio_scaled')\n",
    "        \n",
    "        # √Årea aproximada\n",
    "        if 'diameter_1' in df.columns and 'diameter_2' in df.columns:\n",
    "            df['lesion_area'] = df['diameter_1'] * df['diameter_2']\n",
    "            df['lesion_area'] = df['lesion_area'].fillna(df['lesion_area'].median())\n",
    "            \n",
    "            scaler_area = RobustScaler()\n",
    "            df['lesion_area_scaled'] = scaler_area.fit_transform(df[['lesion_area']])\n",
    "            \n",
    "            self.scalers['lesion_area'] = scaler_area\n",
    "            self.numerical_features.append('lesion_area_scaled')\n",
    "            processed_features.append('lesion_area_scaled')\n",
    "        \n",
    "        # Age groups (binning)\n",
    "        if 'age' in df.columns:\n",
    "            df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 50, 65, 100], \n",
    "                                     labels=['0-18', '19-35', '36-50', '51-65', '66+'])\n",
    "            # Convertir a string antes de fillna para evitar error con categor√≠as\n",
    "            df['age_group'] = df['age_group'].astype(str).replace('nan', 'UNKNOWN')\n",
    "            \n",
    "            le_age = LabelEncoder()\n",
    "            df['age_group_encoded'] = le_age.fit_transform(df['age_group'])\n",
    "            \n",
    "            self.label_encoders['age_group'] = le_age\n",
    "            self.categorical_features.append('age_group_encoded')\n",
    "            self.categorical_dims['age_group_encoded'] = len(le_age.classes_)\n",
    "            processed_features.append('age_group_encoded')\n",
    "        \n",
    "        # Conteo de s√≠ntomas (feature agregada)\n",
    "        symptom_cols = ['itch', 'grew', 'hurt', 'changed', 'bleed', 'elevation']\n",
    "        symptom_encoded = [f'{col}_encoded' for col in symptom_cols if f'{col}_encoded' in df.columns]\n",
    "        \n",
    "        if len(symptom_encoded) > 0:\n",
    "            df['symptom_count'] = df[symptom_encoded].sum(axis=1)\n",
    "            \n",
    "            scaler_symp = RobustScaler()\n",
    "            df['symptom_count_scaled'] = scaler_symp.fit_transform(df[['symptom_count']])\n",
    "            \n",
    "            self.scalers['symptom_count'] = scaler_symp\n",
    "            self.numerical_features.append('symptom_count_scaled')\n",
    "            processed_features.append('symptom_count_scaled')\n",
    "        \n",
    "        # Conteo de factores de riesgo\n",
    "        risk_cols = ['smoke_encoded', 'drink_encoded', 'skin_cancer_history_encoded', \n",
    "                     'cancer_history_encoded']\n",
    "        risk_encoded = [col for col in risk_cols if col in df.columns]\n",
    "        \n",
    "        if len(risk_encoded) > 0:\n",
    "            df['risk_score'] = df[risk_encoded].sum(axis=1)\n",
    "            \n",
    "            scaler_risk = RobustScaler()\n",
    "            df['risk_score_scaled'] = scaler_risk.fit_transform(df[['risk_score']])\n",
    "            \n",
    "            self.scalers['risk_score'] = scaler_risk\n",
    "            self.numerical_features.append('risk_score_scaled')\n",
    "            processed_features.append('risk_score_scaled')\n",
    "        \n",
    "        self.feature_names = processed_features\n",
    "        \n",
    "        # Retornar array con todas las features\n",
    "        X = df[processed_features].values.astype(np.float32)\n",
    "        \n",
    "        print(f\"‚úÖ Preprocesamiento completado:\")\n",
    "        print(f\"   Features categ√≥ricas: {len(self.categorical_features)}\")\n",
    "        print(f\"   Features num√©ricas: {len(self.numerical_features)}\")\n",
    "        print(f\"   Total features: {len(self.feature_names)}\")\n",
    "        print(f\"   Shape: {X.shape}\")\n",
    "        \n",
    "        return X, df\n",
    "    \n",
    "    def transform(self, df):\n",
    "        \"\"\"Transforma nuevos datos usando los ajustes previos\"\"\"\n",
    "        df = df.copy()\n",
    "        processed_features = []\n",
    "        \n",
    "        # Categ√≥ricas\n",
    "        for col, le in self.label_encoders.items():\n",
    "            if col == 'age_group':\n",
    "                df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 50, 65, 100], \n",
    "                                        labels=['0-18', '19-35', '36-50', '51-65', '66+'])\n",
    "                # Convertir a string antes de fillna\n",
    "                df['age_group'] = df['age_group'].astype(str).replace('nan', 'UNKNOWN')\n",
    "                \n",
    "                # Manejar categor√≠as no vistas\n",
    "                df['age_group'] = df['age_group'].apply(\n",
    "                    lambda x: x if x in le.classes_ else 'UNKNOWN'\n",
    "                )\n",
    "                df[f'{col}_encoded'] = le.transform(df['age_group'])\n",
    "            else:\n",
    "                df[col] = df[col].fillna('UNKNOWN')\n",
    "                if df[col].dtype == 'bool':\n",
    "                    df[col] = df[col].astype(str)\n",
    "                \n",
    "                # Manejar categor√≠as no vistas\n",
    "                df[col] = df[col].apply(\n",
    "                    lambda x: x if x in le.classes_ else 'UNKNOWN'\n",
    "                )\n",
    "                df[f'{col}_encoded'] = le.transform(df[col].astype(str))\n",
    "        \n",
    "        # Num√©ricas\n",
    "        for col, scaler in self.scalers.items():\n",
    "            if col in ['diameter_ratio', 'lesion_area', 'symptom_count', 'risk_score']:\n",
    "                # Recalcular features derivadas\n",
    "                if col == 'diameter_ratio':\n",
    "                    df['diameter_ratio'] = df['diameter_1'] / (df['diameter_2'] + 1e-6)\n",
    "                    df['diameter_ratio'] = df['diameter_ratio'].fillna(1.0)\n",
    "                elif col == 'lesion_area':\n",
    "                    df['lesion_area'] = df['diameter_1'] * df['diameter_2']\n",
    "                    df['lesion_area'] = df['lesion_area'].fillna(df['lesion_area'].median())\n",
    "                elif col == 'symptom_count':\n",
    "                    symptom_cols = ['itch_encoded', 'grew_encoded', 'hurt_encoded', \n",
    "                                   'changed_encoded', 'bleed_encoded', 'elevation_encoded']\n",
    "                    symptom_encoded = [c for c in symptom_cols if c in df.columns]\n",
    "                    df['symptom_count'] = df[symptom_encoded].sum(axis=1)\n",
    "                elif col == 'risk_score':\n",
    "                    risk_cols = ['smoke_encoded', 'drink_encoded', \n",
    "                                'skin_cancer_history_encoded', 'cancer_history_encoded']\n",
    "                    risk_encoded = [c for c in risk_cols if c in df.columns]\n",
    "                    df['risk_score'] = df[risk_encoded].sum(axis=1)\n",
    "                \n",
    "                df[f'{col}_scaled'] = scaler.transform(df[[col]])\n",
    "            else:\n",
    "                orig_col = col\n",
    "                df[orig_col] = df[orig_col].fillna(df[orig_col].median())\n",
    "                df[f'{col}_scaled'] = scaler.transform(df[[orig_col]])\n",
    "        \n",
    "        X = df[self.feature_names].values.astype(np.float32)\n",
    "        return X, df\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "preprocessor = MetadataPreprocessor()\n",
    "X_metadata, df_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "print(f\"\\nüìä Metadata shape: {X_metadata.shape}\")\n",
    "print(f\"   Rango de valores: [{X_metadata.min():.3f}, {X_metadata.max():.3f}]\")\n",
    "\n",
    "# Guardar preprocessor\n",
    "import pickle\n",
    "with open(Config.OUTPUT_DIR / 'metadata_preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "\n",
    "print(\"‚úÖ Preprocessor guardado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 4: AUGMENTATIONS AVANZADAS Y DATASET\n",
    "# ============================================================================\n",
    "\n",
    "class AdvancedAugmentation:\n",
    "    \"\"\"Augmentations de √∫ltima generaci√≥n para dermatolog√≠a\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=512, mode='train'):\n",
    "        self.img_size = img_size\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == 'train':\n",
    "            self.transform = A.Compose([\n",
    "                # Redimensionamiento\n",
    "                A.Resize(img_size, img_size),\n",
    "                \n",
    "                # Augmentations geom√©tricas\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.ShiftScaleRotate(\n",
    "                    shift_limit=0.1,\n",
    "                    scale_limit=0.2,\n",
    "                    rotate_limit=45,\n",
    "                    border_mode=0,\n",
    "                    p=0.7\n",
    "                ),\n",
    "                \n",
    "                # Distorsiones √≥pticas (importantes para lesiones)\n",
    "                A.OneOf([\n",
    "                    A.ElasticTransform(alpha=1, sigma=50, p=1.0),\n",
    "                    A.GridDistortion(num_steps=5, distort_limit=0.3, p=1.0),\n",
    "                    A.OpticalDistortion(distort_limit=0.5, shift_limit=0.5, p=1.0),\n",
    "                ], p=0.3),\n",
    "                \n",
    "                # Cambios de perspectiva\n",
    "                A.Perspective(scale=(0.05, 0.1), p=0.3),\n",
    "                \n",
    "                # Augmentations de color (cr√≠ticas para dermatolog√≠a)\n",
    "                A.OneOf([\n",
    "                    A.HueSaturationValue(\n",
    "                        hue_shift_limit=20,\n",
    "                        sat_shift_limit=30,\n",
    "                        val_shift_limit=20,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                    A.RGBShift(\n",
    "                        r_shift_limit=20,\n",
    "                        g_shift_limit=20,\n",
    "                        b_shift_limit=20,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                    A.ColorJitter(\n",
    "                        brightness=0.2,\n",
    "                        contrast=0.2,\n",
    "                        saturation=0.2,\n",
    "                        hue=0.1,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                ], p=0.8),\n",
    "                \n",
    "                # Simulaci√≥n de condiciones de iluminaci√≥n\n",
    "                A.OneOf([\n",
    "                    A.RandomBrightnessContrast(\n",
    "                        brightness_limit=0.3,\n",
    "                        contrast_limit=0.3,\n",
    "                        p=1.0\n",
    "                    ),\n",
    "                    A.RandomGamma(gamma_limit=(80, 120), p=1.0),\n",
    "                    A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "                ], p=0.5),\n",
    "                \n",
    "                # Efectos de desenfoque (importante para diferentes calidades de imagen)\n",
    "                A.OneOf([\n",
    "                    A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                    A.MotionBlur(blur_limit=7, p=1.0),\n",
    "                    A.MedianBlur(blur_limit=7, p=1.0),\n",
    "                ], p=0.2),\n",
    "                \n",
    "                # Ruido (simula diferentes calidades de c√°mara)\n",
    "                A.OneOf([\n",
    "                    A.GaussNoise(var_limit=(10.0, 50.0), p=1.0),\n",
    "                    A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=1.0),\n",
    "                    A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=1.0),\n",
    "                ], p=0.2),\n",
    "                \n",
    "                # Compresi√≥n JPEG (realista)\n",
    "                A.ImageCompression(quality_lower=75, quality_upper=100, p=0.3),\n",
    "                \n",
    "                # Cutout avanzado\n",
    "                A.CoarseDropout(\n",
    "                    max_holes=8,\n",
    "                    max_height=int(img_size * 0.15),\n",
    "                    max_width=int(img_size * 0.15),\n",
    "                    min_holes=1,\n",
    "                    fill_value=0,\n",
    "                    p=0.3\n",
    "                ),\n",
    "                \n",
    "                # Normalizaci√≥n\n",
    "                A.Normalize(\n",
    "                    mean=Config.IMG_MEAN,\n",
    "                    std=Config.IMG_STD,\n",
    "                    max_pixel_value=255.0\n",
    "                ),\n",
    "                \n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        \n",
    "        else:  # val/test\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.Normalize(\n",
    "                    mean=Config.IMG_MEAN,\n",
    "                    std=Config.IMG_STD,\n",
    "                    max_pixel_value=255.0\n",
    "                ),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = np.array(Image.open(image).convert('RGB'))\n",
    "        elif isinstance(image, Image.Image):\n",
    "            image = np.array(image.convert('RGB'))\n",
    "        \n",
    "        return self.transform(image=image)['image']\n",
    "\n",
    "\n",
    "class TTATransform:\n",
    "    \"\"\"Test-Time Augmentation transforms\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=512):\n",
    "        self.img_size = img_size\n",
    "        self.transforms = [\n",
    "            # Original\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Flip horizontal\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.HorizontalFlip(p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Flip vertical\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.VerticalFlip(p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Rotate 90\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.Rotate(limit=90, p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ]),\n",
    "            # Brightness\n",
    "            A.Compose([\n",
    "                A.Resize(img_size, img_size),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "                A.Normalize(mean=Config.IMG_MEAN, std=Config.IMG_STD),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "        ]\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        if isinstance(image, str):\n",
    "            image = np.array(Image.open(image).convert('RGB'))\n",
    "        elif isinstance(image, Image.Image):\n",
    "            image = np.array(image.convert('RGB'))\n",
    "        \n",
    "        return [t(image=image)['image'] for t in self.transforms]\n",
    "\n",
    "\n",
    "class SkinCancerDataset(Dataset):\n",
    "    \"\"\"Dataset avanzado con soporte para mixup y cutmix\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, metadata, labels, transform=None, mode='train'):\n",
    "        self.image_paths = image_paths\n",
    "        self.metadata = torch.FloatTensor(metadata)\n",
    "        self.labels = torch.LongTensor(labels)\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Cargar imagen\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = T.ToTensor()(image)\n",
    "        \n",
    "        metadata = self.metadata[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "\n",
    "def mixup_data(x_img, x_meta, y, alpha=0.4):\n",
    "    \"\"\"Mixup augmentation para imagen y metadata\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x_img.size(0)\n",
    "    index = torch.randperm(batch_size).to(x_img.device)\n",
    "    \n",
    "    mixed_img = lam * x_img + (1 - lam) * x_img[index]\n",
    "    mixed_meta = lam * x_meta + (1 - lam) * x_meta[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_img, mixed_meta, y_a, y_b, lam\n",
    "\n",
    "\n",
    "def cutmix_data(x_img, x_meta, y, alpha=1.0):\n",
    "    \"\"\"CutMix augmentation\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    \n",
    "    batch_size = x_img.size(0)\n",
    "    index = torch.randperm(batch_size).to(x_img.device)\n",
    "    \n",
    "    _, _, h, w = x_img.size()\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(w * cut_rat)\n",
    "    cut_h = int(h * cut_rat)\n",
    "    \n",
    "    cx = np.random.randint(w)\n",
    "    cy = np.random.randint(h)\n",
    "    \n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, w)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, h)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, w)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, h)\n",
    "    \n",
    "    mixed_img = x_img.clone()\n",
    "    mixed_img[:, :, bby1:bby2, bbx1:bbx2] = x_img[index, :, bby1:bby2, bbx1:bbx2]\n",
    "    \n",
    "    # Metadata no se mezcla en CutMix\n",
    "    mixed_meta = x_meta\n",
    "    \n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (w * h))\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_img, mixed_meta, y_a, y_b, lam\n",
    "\n",
    "\n",
    "print(\"‚úÖ Augmentations y Dataset configurados\")\n",
    "print(f\"   Pol√≠ticas de augmentation: Train (avanzado) / Val (b√°sico)\")\n",
    "print(f\"   TTA transforms: {Config.TTA_TRANSFORMS}\")\n",
    "print(f\"   Mixup alpha: {Config.MIXUP_ALPHA}\")\n",
    "print(f\"   CutMix alpha: {Config.CUTMIX_ALPHA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 5: ARQUITECTURA DEL MODELO - FUSI√ìN MULTIMODAL\n",
    "# ============================================================================\n",
    "\n",
    "class TabTransformer(nn.Module):\n",
    "    \"\"\"Transformer para datos tabulares con embeddings categ√≥ricos\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 categorical_dims,\n",
    "                 numerical_features,\n",
    "                 embed_dim=128,\n",
    "                 num_heads=8,\n",
    "                 num_layers=6,\n",
    "                 dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.categorical_dims = categorical_dims\n",
    "        self.num_numerical = numerical_features\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Embeddings para features categ√≥ricas\n",
    "        self.categorical_embeddings = nn.ModuleDict({\n",
    "            name: nn.Embedding(dim + 1, embed_dim)\n",
    "            for name, dim in categorical_dims.items()\n",
    "        })\n",
    "        \n",
    "        # Proyecci√≥n para features num√©ricas\n",
    "        if self.num_numerical > 0:\n",
    "            self.numerical_projection = nn.Sequential(\n",
    "                nn.Linear(self.num_numerical, embed_dim),\n",
    "                nn.LayerNorm(embed_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        \n",
    "        # Positional encoding\n",
    "        total_features = len(categorical_dims) + (1 if self.num_numerical > 0 else 0)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, total_features, embed_dim))\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=embed_dim * 4,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Layer normalization final\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "    def forward(self, x, cat_indices):\n",
    "        \"\"\"\n",
    "        x: tensor [batch, total_features]\n",
    "        cat_indices: dict con √≠ndices de cada feature categ√≥rica\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        \n",
    "        # Embeddings categ√≥ricos\n",
    "        for name, dim in self.categorical_dims.items():\n",
    "            idx = cat_indices[name]\n",
    "            cat_vals = x[:, idx].long()\n",
    "            \n",
    "            # ‚ö†Ô∏è CLIP CR√çTICO: Asegurar que est√©n en rango [0, dim-1]\n",
    "            cat_vals = torch.clamp(cat_vals, 0, dim - 1)\n",
    "            \n",
    "            emb = self.categorical_embeddings[name](cat_vals)\n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        # Proyecci√≥n de features num√©ricas\n",
    "        if self.num_numerical > 0:\n",
    "            num_start = len(self.categorical_dims)\n",
    "            num_features = x[:, num_start:]\n",
    "            num_emb = self.numerical_projection(num_features)\n",
    "            embeddings.append(num_emb)\n",
    "        \n",
    "        # Stack embeddings\n",
    "        x = torch.stack(embeddings, dim=1)  # [batch, n_features, embed_dim]\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_embedding\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Global average pooling\n",
    "        x = x.mean(dim=1)  # [batch, embed_dim]\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class MultimodalSkinCancerModel(nn.Module):\n",
    "    \"\"\"Modelo multimodal: EfficientNetV2 + TabTransformer + Late Fusion\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_classes,\n",
    "                 categorical_dims,\n",
    "                 num_numerical_features,\n",
    "                 img_model_name='tf_efficientnetv2_m',\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ===== BRANCH 1: IMAGE MODEL (EfficientNetV2) =====\n",
    "        self.image_model = timm.create_model(\n",
    "            img_model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,  # Remove classifier\n",
    "            drop_rate=Config.DROP_RATE,\n",
    "            drop_path_rate=Config.DROP_PATH_RATE\n",
    "        )\n",
    "        \n",
    "        # Obtener dimensi√≥n de salida\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, Config.IMG_SIZE, Config.IMG_SIZE)\n",
    "            img_features = self.image_model(dummy_input)\n",
    "            self.img_feature_dim = img_features.shape[1]\n",
    "        \n",
    "        print(f\"‚úÖ EfficientNetV2 cargado: {self.img_feature_dim} features\")\n",
    "        \n",
    "        # ===== BRANCH 2: METADATA MODEL (TabTransformer) =====\n",
    "        self.metadata_model = TabTransformer(\n",
    "            categorical_dims=categorical_dims,\n",
    "            numerical_features=num_numerical_features,\n",
    "            embed_dim=Config.TAB_EMBED_DIM,\n",
    "            num_heads=Config.TAB_NUM_HEADS,\n",
    "            num_layers=Config.TAB_NUM_LAYERS,\n",
    "            dropout=Config.TAB_DROPOUT\n",
    "        )\n",
    "        \n",
    "        self.meta_feature_dim = Config.TAB_EMBED_DIM\n",
    "        \n",
    "        print(f\"‚úÖ TabTransformer construido: {self.meta_feature_dim} features\")\n",
    "        \n",
    "        # ===== FUSION HEAD =====\n",
    "        fusion_input_dim = self.img_feature_dim + self.meta_feature_dim\n",
    "        \n",
    "        fusion_layers = []\n",
    "        prev_dim = fusion_input_dim\n",
    "        \n",
    "        for hidden_dim in Config.FUSION_HIDDEN_DIMS:\n",
    "            fusion_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(Config.FUSION_DROPOUT)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.fusion_head = nn.Sequential(*fusion_layers)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Linear(prev_dim, num_classes)\n",
    "        \n",
    "        # Attention weights para fusi√≥n interpretable (opcional)\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(fusion_input_dim, 2),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Fusion head: {fusion_input_dim} -> {prev_dim} -> {num_classes}\")\n",
    "        \n",
    "        # Inicializaci√≥n de pesos\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Inicializaci√≥n Xavier/Kaiming\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, images, metadata, cat_indices):\n",
    "        \"\"\"\n",
    "        images: [batch, 3, H, W]\n",
    "        metadata: [batch, n_features]\n",
    "        cat_indices: dict con √≠ndices de features categ√≥ricas\n",
    "        \"\"\"\n",
    "        # Image features\n",
    "        img_features = self.image_model(images)  # [batch, img_dim]\n",
    "        \n",
    "        # Metadata features\n",
    "        meta_features = self.metadata_model(metadata, cat_indices)  # [batch, meta_dim]\n",
    "        \n",
    "        # Concatenate\n",
    "        fused = torch.cat([img_features, meta_features], dim=1)\n",
    "        \n",
    "        # Optional: Attention-weighted fusion\n",
    "        # att_weights = self.attention(fused)  # [batch, 2]\n",
    "        # img_weight = att_weights[:, 0:1]\n",
    "        # meta_weight = att_weights[:, 1:2]\n",
    "        # fused = torch.cat([\n",
    "        #     img_features * img_weight, \n",
    "        #     meta_features * meta_weight\n",
    "        # ], dim=1)\n",
    "        \n",
    "        # Fusion head\n",
    "        fused = self.fusion_head(fused)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(fused)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def freeze_image_backbone(self):\n",
    "        \"\"\"Congela el backbone de imagen para fine-tuning\"\"\"\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    def unfreeze_image_backbone(self):\n",
    "        \"\"\"Descongela el backbone de imagen\"\"\"\n",
    "        for param in self.image_model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "\n",
    "# Funci√≥n para crear el modelo\n",
    "def create_model(num_classes, categorical_dims, num_numerical_features):\n",
    "    \"\"\"Factory function para crear el modelo\"\"\"\n",
    "    model = MultimodalSkinCancerModel(\n",
    "        num_classes=num_classes,\n",
    "        categorical_dims=categorical_dims,\n",
    "        num_numerical_features=num_numerical_features,\n",
    "        img_model_name=Config.EFFICIENTNET_MODEL,\n",
    "        pretrained=Config.USE_PRETRAINED\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Contar par√°metros\n",
    "def count_parameters(model):\n",
    "    \"\"\"Cuenta par√°metros entrenables y totales\"\"\"\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    return trainable, total\n",
    "\n",
    "\n",
    "print(\"‚úÖ Arquitectura del modelo definida\")\n",
    "print(f\"   Modelo de imagen: {Config.EFFICIENTNET_MODEL}\")\n",
    "print(f\"   TabTransformer: {Config.TAB_NUM_LAYERS} layers, {Config.TAB_NUM_HEADS} heads\")\n",
    "print(f\"   Fusion dims: {Config.FUSION_HIDDEN_DIMS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 6: LOSS FUNCTIONS Y M√âTRICAS AVANZADAS\n",
    "# ============================================================================\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"Focal Loss para desbalanceo de clases\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"Cross Entropy con Label Smoothing\"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        n_classes = pred.size(1)\n",
    "        log_pred = F.log_softmax(pred, dim=1)\n",
    "        \n",
    "        loss = -log_pred.sum(dim=1).mean()\n",
    "        nll = F.nll_loss(log_pred, target, reduction='mean')\n",
    "        \n",
    "        return self.smoothing * (loss / n_classes) + (1 - self.smoothing) * nll\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combinaci√≥n de m√∫ltiples loss functions\"\"\"\n",
    "    \n",
    "    def __init__(self, class_weights=None, focal_gamma=2.0, label_smoothing=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Focal loss para desbalanceo\n",
    "        self.focal_loss = FocalLoss(alpha=class_weights, gamma=focal_gamma)\n",
    "        \n",
    "        # Label smoothing para regularizaci√≥n\n",
    "        self.ls_loss = LabelSmoothingCrossEntropy(smoothing=label_smoothing)\n",
    "        \n",
    "        # Pesos\n",
    "        self.focal_weight = 0.7\n",
    "        self.ls_weight = 0.3\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        focal = self.focal_loss(pred, target)\n",
    "        ls = self.ls_loss(pred, target)\n",
    "        \n",
    "        return self.focal_weight * focal + self.ls_weight * ls\n",
    "\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Loss para mixup/cutmix\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "class MetricsTracker:\n",
    "    \"\"\"Seguimiento de m√©tricas durante entrenamiento\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, class_names):\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.predictions = []\n",
    "        self.targets = []\n",
    "        self.losses = []\n",
    "    \n",
    "    def update(self, preds, targets, loss):\n",
    "        \"\"\"\n",
    "        preds: logits [batch, num_classes]\n",
    "        targets: labels [batch]\n",
    "        loss: scalar\n",
    "        \"\"\"\n",
    "        pred_classes = torch.argmax(preds, dim=1)\n",
    "        \n",
    "        self.predictions.extend(pred_classes.cpu().numpy())\n",
    "        self.targets.extend(targets.cpu().numpy())\n",
    "        self.losses.append(loss)\n",
    "    \n",
    "    def compute(self):\n",
    "        \"\"\"Calcula todas las m√©tricas\"\"\"\n",
    "        preds = np.array(self.predictions)\n",
    "        targets = np.array(self.targets)\n",
    "        \n",
    "        # Accuracy\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        \n",
    "        # M√©tricas por clase\n",
    "        precision = precision_score(targets, preds, average='weighted', zero_division=0)\n",
    "        recall = recall_score(targets, preds, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(targets, preds, average='weighted', zero_division=0)\n",
    "        \n",
    "        # M√©tricas macro (importante para desbalanceo)\n",
    "        precision_macro = precision_score(targets, preds, average='macro', zero_division=0)\n",
    "        recall_macro = recall_score(targets, preds, average='macro', zero_division=0)\n",
    "        f1_macro = f1_score(targets, preds, average='macro', zero_division=0)\n",
    "        \n",
    "        # Loss promedio\n",
    "        avg_loss = np.mean(self.losses)\n",
    "        \n",
    "        # Matriz de confusi√≥n\n",
    "        cm = confusion_matrix(targets, preds)\n",
    "        \n",
    "        # Per-class metrics\n",
    "        per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "        \n",
    "        metrics = {\n",
    "            'loss': avg_loss,\n",
    "            'accuracy': acc,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'precision_macro': precision_macro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'confusion_matrix': cm,\n",
    "            'per_class_accuracy': dict(zip(self.class_names, per_class_acc))\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def print_metrics(self, metrics, prefix=''):\n",
    "        \"\"\"Imprime m√©tricas de forma legible\"\"\"\n",
    "        print(f\"\\n{prefix} M√©tricas:\")\n",
    "        print(f\"  Loss: {metrics['loss']:.4f}\")\n",
    "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Precision (weighted): {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall (weighted): {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1-Score (weighted): {metrics['f1']:.4f}\")\n",
    "        print(f\"  Precision (macro): {metrics['precision_macro']:.4f}\")\n",
    "        print(f\"  Recall (macro): {metrics['recall_macro']:.4f}\")\n",
    "        print(f\"  F1-Score (macro): {metrics['f1_macro']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n  Accuracy por clase:\")\n",
    "        for class_name, acc in metrics['per_class_accuracy'].items():\n",
    "            print(f\"    {class_name}: {acc:.4f}\")\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, save_path=None):\n",
    "    \"\"\"Visualiza matriz de confusi√≥n\"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Normalizar\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(\n",
    "        cm_norm,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='Blues',\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "        cbar_kws={'label': 'Proporci√≥n'}\n",
    "    )\n",
    "    \n",
    "    plt.title('Matriz de Confusi√≥n Normalizada', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Verdadero', fontsize=12)\n",
    "    plt.xlabel('Predicho', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_history(history, save_path=None):\n",
    "    \"\"\"Visualiza historial de entrenamiento\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val', linewidth=2)\n",
    "    axes[0, 0].set_title('Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 1].plot(history['train_acc'], label='Train', linewidth=2)\n",
    "    axes[0, 1].plot(history['val_acc'], label='Val', linewidth=2)\n",
    "    axes[0, 1].set_title('Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(alpha=0.3)\n",
    "    \n",
    "    # F1 Score\n",
    "    axes[1, 0].plot(history['train_f1'], label='Train', linewidth=2)\n",
    "    axes[1, 0].plot(history['val_f1'], label='Val', linewidth=2)\n",
    "    axes[1, 0].set_title('F1-Score (Weighted)', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('F1-Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[1, 1].plot(history['lr'], linewidth=2, color='green')\n",
    "    axes[1, 1].set_title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('LR')\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úÖ Loss functions y m√©tricas configuradas\")\n",
    "print(\"   - Focal Loss (para desbalanceo)\")\n",
    "print(\"   - Label Smoothing (regularizaci√≥n)\")\n",
    "print(\"   - Combined Loss (0.7*Focal + 0.3*LS)\")\n",
    "print(\"   - M√©tricas: Accuracy, Precision, Recall, F1 (weighted y macro)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a6df5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 7: PREPARACI√ìN Y BALANCEO DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "# Encode target labels\n",
    "le_target = LabelEncoder()\n",
    "df_processed['diagnostic_encoded'] = le_target.fit_transform(df_processed['diagnostic'])\n",
    "\n",
    "class_names = le_target.classes_\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"üéØ Clases detectadas: {num_classes}\")\n",
    "for i, name in enumerate(class_names):\n",
    "    count = (df_processed['diagnostic_encoded'] == i).sum()\n",
    "    print(f\"   {i}: {name} - {count} muestras\")\n",
    "\n",
    "# Preparar arrays\n",
    "image_paths = df_processed['image_path'].values\n",
    "labels = df_processed['diagnostic_encoded'].values\n",
    "\n",
    "# Crear √≠ndices de features categ√≥ricas para TabTransformer\n",
    "cat_feature_indices = {}\n",
    "idx = 0\n",
    "for feat in preprocessor.categorical_features:\n",
    "    cat_feature_indices[feat] = idx\n",
    "    idx += 1\n",
    "\n",
    "print(f\"\\nüìä Features para TabTransformer:\")\n",
    "print(f\"   Categ√≥ricas: {len(preprocessor.categorical_features)}\")\n",
    "print(f\"   Num√©ricas: {len(preprocessor.numerical_features)}\")\n",
    "print(f\"   Total: {X_metadata.shape[1]}\")\n",
    "\n",
    "# Split estratificado train/val/test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    np.arange(len(image_paths)),\n",
    "    labels,\n",
    "    test_size=0.15,\n",
    "    stratify=labels,\n",
    "    random_state=Config.SEED\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    test_size=0.15 / 0.85,  # ~15% of total\n",
    "    stratify=y_temp,\n",
    "    random_state=Config.SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nüì¶ Splits:\")\n",
    "print(f\"   Train: {len(X_train)} ({len(X_train)/len(labels)*100:.1f}%)\")\n",
    "print(f\"   Val: {len(X_val)} ({len(X_val)/len(labels)*100:.1f}%)\")\n",
    "print(f\"   Test: {len(X_test)} ({len(X_test)/len(labels)*100:.1f}%)\")\n",
    "\n",
    "# Distribuci√≥n por clase en cada split\n",
    "print(f\"\\nüìä Distribuci√≥n por split:\")\n",
    "for split_name, split_indices in [('Train', X_train), ('Val', X_val), ('Test', X_test)]:\n",
    "    print(f\"\\n{split_name}:\")\n",
    "    split_labels = labels[split_indices]\n",
    "    for i, name in enumerate(class_names):\n",
    "        count = (split_labels == i).sum()\n",
    "        pct = count / len(split_labels) * 100\n",
    "        print(f\"   {name}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Calcular class weights para loss\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Class weights calculados:\")\n",
    "for i, (name, weight) in enumerate(zip(class_names, class_weights)):\n",
    "    print(f\"   {name}: {weight:.3f}\")\n",
    "\n",
    "# OPCIONAL: SMOTE para balancear train set (solo si desbalanceo es extremo)\n",
    "# Si el desbalanceo es > 10x, aplicar SMOTE\n",
    "max_samples = np.max(np.bincount(y_train))\n",
    "min_samples = np.min(np.bincount(y_train))\n",
    "imbalance_ratio = max_samples / min_samples\n",
    "\n",
    "print(f\"\\nüìä Ratio de desbalanceo en train: {imbalance_ratio:.2f}x\")\n",
    "\n",
    "if imbalance_ratio > 10:\n",
    "    print(\"‚ö†Ô∏è Desbalanceo alto detectado. Aplicando SMOTE...\")\n",
    "    \n",
    "    # SMOTE solo se puede aplicar a metadata, no a im√°genes\n",
    "    # Estrategia: oversample los √≠ndices\n",
    "    \n",
    "    # Crear estrategia de oversampling\n",
    "    sampling_strategy = {}\n",
    "    for i in range(num_classes):\n",
    "        count = (y_train == i).sum()\n",
    "        if count < max_samples * 0.5:  # Clases muy minoritarias\n",
    "            sampling_strategy[i] = int(max_samples * 0.7)\n",
    "    \n",
    "    if len(sampling_strategy) > 0:\n",
    "        smote = SMOTE(\n",
    "            sampling_strategy=sampling_strategy,\n",
    "            random_state=Config.SEED,\n",
    "            k_neighbors=min(5, min_samples - 1)\n",
    "        )\n",
    "        \n",
    "        # Aplicar SMOTE\n",
    "        X_meta_train = X_metadata[X_train]\n",
    "        X_meta_resampled, y_train_resampled = smote.fit_resample(X_meta_train, y_train)\n",
    "        \n",
    "        # Ahora necesitamos duplicar las im√°genes correspondientes\n",
    "        # Para esto, mapeamos los √≠ndices originales\n",
    "        original_indices = X_train.copy()\n",
    "        \n",
    "        # Encontrar qu√© muestras fueron duplicadas\n",
    "        n_original = len(X_train)\n",
    "        n_resampled = len(y_train_resampled)\n",
    "        n_synthetic = n_resampled - n_original\n",
    "        \n",
    "        print(f\"   Muestras originales: {n_original}\")\n",
    "        print(f\"   Muestras despu√©s de SMOTE: {n_resampled}\")\n",
    "        print(f\"   Muestras sint√©ticas: {n_synthetic}\")\n",
    "        \n",
    "        # Para las sint√©ticas, asignamos la imagen m√°s cercana de la misma clase\n",
    "        # (simplificaci√≥n: usar √≠ndices aleatorios de la misma clase)\n",
    "        synthetic_indices = []\n",
    "        for i in range(n_synthetic):\n",
    "            # Obtener clase de la muestra sint√©tica\n",
    "            synthetic_label = y_train_resampled[n_original + i]\n",
    "            # Seleccionar √≠ndice aleatorio de la misma clase\n",
    "            class_indices = original_indices[y_train == synthetic_label]\n",
    "            synthetic_idx = np.random.choice(class_indices)\n",
    "            synthetic_indices.append(synthetic_idx)\n",
    "        \n",
    "        # Combinar √≠ndices\n",
    "        X_train_final = np.concatenate([original_indices, synthetic_indices])\n",
    "        y_train_final = y_train_resampled\n",
    "        X_meta_train_final = X_meta_resampled\n",
    "        \n",
    "        print(f\"\\n‚úÖ SMOTE aplicado. Nuevo tama√±o de train: {len(X_train_final)}\")\n",
    "        print(\"   Distribuci√≥n despu√©s de SMOTE:\")\n",
    "        for i, name in enumerate(class_names):\n",
    "            count = (y_train_final == i).sum()\n",
    "            print(f\"   {name}: {count}\")\n",
    "    else:\n",
    "        print(\"   No se requiere SMOTE (desbalanceo moderado)\")\n",
    "        X_train_final = X_train\n",
    "        y_train_final = y_train\n",
    "        X_meta_train_final = X_metadata[X_train]\n",
    "else:\n",
    "    print(\"‚úÖ Desbalanceo aceptable. No se aplica SMOTE.\")\n",
    "    X_train_final = X_train\n",
    "    y_train_final = y_train\n",
    "    X_meta_train_final = X_metadata[X_train]\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset = SkinCancerDataset(\n",
    "    image_paths=image_paths[X_train_final],\n",
    "    metadata=X_meta_train_final,\n",
    "    labels=y_train_final,\n",
    "    transform=AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='train'),\n",
    "    mode='train'\n",
    ")\n",
    "\n",
    "val_dataset = SkinCancerDataset(\n",
    "    image_paths=image_paths[X_val],\n",
    "    metadata=X_metadata[X_val],\n",
    "    labels=y_val,\n",
    "    transform=AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='val'),\n",
    "    mode='val'\n",
    ")\n",
    "\n",
    "test_dataset = SkinCancerDataset(\n",
    "    image_paths=image_paths[X_test],\n",
    "    metadata=X_metadata[X_test],\n",
    "    labels=y_test,\n",
    "    transform=AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='val'),\n",
    "    mode='test'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets creados:\")\n",
    "print(f\"   Train: {len(train_dataset)}\")\n",
    "print(f\"   Val: {len(val_dataset)}\")\n",
    "print(f\"   Test: {len(test_dataset)}\")\n",
    "\n",
    "# Crear dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    pin_memory=Config.PIN_MEMORY,\n",
    "    drop_last=True  # Para mixup/cutmix\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    pin_memory=Config.PIN_MEMORY\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=Config.NUM_WORKERS,\n",
    "    pin_memory=Config.PIN_MEMORY\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ DataLoaders creados:\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches: {len(val_loader)}\")\n",
    "print(f\"   Test batches: {len(test_loader)}\")\n",
    "\n",
    "# Guardar informaci√≥n para posterior uso\n",
    "dataset_info = {\n",
    "    'class_names': class_names.tolist(),\n",
    "    'num_classes': num_classes,\n",
    "    'class_weights': class_weights.cpu().numpy().tolist(),\n",
    "    'train_size': len(train_dataset),\n",
    "    'val_size': len(val_dataset),\n",
    "    'test_size': len(test_dataset),\n",
    "    'cat_feature_indices': cat_feature_indices,\n",
    "    'categorical_dims': preprocessor.categorical_dims\n",
    "}\n",
    "\n",
    "with open(Config.OUTPUT_DIR / 'dataset_info.json', 'w') as f:\n",
    "    json.dump(dataset_info, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Informaci√≥n del dataset guardada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 8: TRAINING LOOP COMPLETO CON T√âCNICAS AVANZADAS\n",
    "# ============================================================================\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Trainer avanzado con todas las optimizaciones\"\"\"\n",
    "    \n",
    "    def __init__(self, model, train_loader, val_loader, criterion, optimizer, \n",
    "                 scheduler, cat_indices, device, config):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.cat_indices = cat_indices\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        \n",
    "        # Gradient scaler para AMP\n",
    "        self.scaler = torch.cuda.amp.GradScaler() if config.AMP_ENABLED else None\n",
    "        \n",
    "        # History\n",
    "        self.history = {\n",
    "            'train_loss': [], 'val_loss': [],\n",
    "            'train_acc': [], 'val_acc': [],\n",
    "            'train_f1': [], 'val_f1': [],\n",
    "            'lr': []\n",
    "        }\n",
    "        \n",
    "        # Best model tracking\n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_val_f1 = 0.0\n",
    "        self.best_epoch = 0\n",
    "        self.patience_counter = 0\n",
    "        \n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"Entrena una √©poca\"\"\"\n",
    "        self.model.train()\n",
    "        metrics_tracker = MetricsTracker(len(class_names), class_names)\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch+1}/{self.config.EPOCHS} [Train]')\n",
    "        \n",
    "        for batch_idx, batch in enumerate(pbar):\n",
    "            images = batch['image'].to(self.device)\n",
    "            metadata = batch['metadata'].to(self.device)\n",
    "            labels = batch['label'].to(self.device)\n",
    "            \n",
    "            # Aplicar mixup/cutmix con probabilidad\n",
    "            use_mixup = np.random.rand() < self.config.MIXUP_PROB\n",
    "            \n",
    "            if use_mixup:\n",
    "                if np.random.rand() < 0.5:  # 50% mixup, 50% cutmix\n",
    "                    images, metadata, labels_a, labels_b, lam = mixup_data(\n",
    "                        images, metadata, labels, alpha=self.config.MIXUP_ALPHA\n",
    "                    )\n",
    "                else:\n",
    "                    images, metadata, labels_a, labels_b, lam = cutmix_data(\n",
    "                        images, metadata, labels, alpha=self.config.CUTMIX_ALPHA\n",
    "                    )\n",
    "            \n",
    "            # Forward pass con AMP\n",
    "            with torch.cuda.amp.autocast(enabled=self.config.AMP_ENABLED):\n",
    "                logits = self.model(images, metadata, self.cat_indices)\n",
    "                \n",
    "                if use_mixup:\n",
    "                    loss = mixup_criterion(self.criterion, logits, labels_a, labels_b, lam)\n",
    "                else:\n",
    "                    loss = self.criterion(logits, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            if self.scaler is not None:\n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            if use_mixup:\n",
    "                # Para mixup, usamos las etiquetas originales para m√©tricas\n",
    "                metrics_tracker.update(logits.detach(), labels_a, loss.item())\n",
    "            else:\n",
    "                metrics_tracker.update(logits.detach(), labels, loss.item())\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Compute epoch metrics\n",
    "        train_metrics = metrics_tracker.compute()\n",
    "        \n",
    "        return train_metrics\n",
    "    \n",
    "    def validate(self, epoch):\n",
    "        \"\"\"Valida el modelo\"\"\"\n",
    "        self.model.eval()\n",
    "        metrics_tracker = MetricsTracker(len(class_names), class_names)\n",
    "        \n",
    "        pbar = tqdm(self.val_loader, desc=f'Epoch {epoch+1}/{self.config.EPOCHS} [Val]')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in pbar:\n",
    "                images = batch['image'].to(self.device)\n",
    "                metadata = batch['metadata'].to(self.device)\n",
    "                labels = batch['label'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                with torch.cuda.amp.autocast(enabled=self.config.AMP_ENABLED):\n",
    "                    logits = self.model(images, metadata, self.cat_indices)\n",
    "                    loss = self.criterion(logits, labels)\n",
    "                \n",
    "                # Update metrics\n",
    "                metrics_tracker.update(logits, labels, loss.item())\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Compute epoch metrics\n",
    "        val_metrics = metrics_tracker.compute()\n",
    "        \n",
    "        return val_metrics\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Loop de entrenamiento completo\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"üöÄ INICIANDO ENTRENAMIENTO\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for epoch in range(self.config.EPOCHS):\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"Epoch {epoch+1}/{self.config.EPOCHS}\")\n",
    "            print(f\"{'='*80}\")\n",
    "            \n",
    "            # Train\n",
    "            train_metrics = self.train_epoch(epoch)\n",
    "            \n",
    "            # Validate\n",
    "            val_metrics = self.validate(epoch)\n",
    "            \n",
    "            # Scheduler step\n",
    "            if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                self.scheduler.step(val_metrics['loss'])\n",
    "            else:\n",
    "                self.scheduler.step()\n",
    "            \n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Update history\n",
    "            self.history['train_loss'].append(train_metrics['loss'])\n",
    "            self.history['val_loss'].append(val_metrics['loss'])\n",
    "            self.history['train_acc'].append(train_metrics['accuracy'])\n",
    "            self.history['val_acc'].append(val_metrics['accuracy'])\n",
    "            self.history['train_f1'].append(train_metrics['f1'])\n",
    "            self.history['val_f1'].append(val_metrics['f1'])\n",
    "            self.history['lr'].append(current_lr)\n",
    "            \n",
    "            # Print metrics\n",
    "            print(f\"\\nüìä TRAIN - Loss: {train_metrics['loss']:.4f} | \"\n",
    "                  f\"Acc: {train_metrics['accuracy']:.4f} | F1: {train_metrics['f1']:.4f}\")\n",
    "            print(f\"üìä VAL   - Loss: {val_metrics['loss']:.4f} | \"\n",
    "                  f\"Acc: {val_metrics['accuracy']:.4f} | F1: {val_metrics['f1']:.4f}\")\n",
    "            print(f\"üìà LR: {current_lr:.2e}\")\n",
    "            \n",
    "            # Save best model\n",
    "            is_best = val_metrics['accuracy'] > self.best_val_acc\n",
    "            \n",
    "            if is_best:\n",
    "                self.best_val_acc = val_metrics['accuracy']\n",
    "                self.best_val_f1 = val_metrics['f1']\n",
    "                self.best_epoch = epoch\n",
    "                self.patience_counter = 0\n",
    "                \n",
    "                # Save checkpoint\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                    'best_val_acc': self.best_val_acc,\n",
    "                    'best_val_f1': self.best_val_f1,\n",
    "                    'history': self.history,\n",
    "                }\n",
    "                \n",
    "                torch.save(checkpoint, self.config.MODELS_DIR / 'best_model.pth')\n",
    "                print(f\"üíæ Mejor modelo guardado! Val Acc: {self.best_val_acc:.4f}\")\n",
    "            else:\n",
    "                self.patience_counter += 1\n",
    "                print(f\"‚è≥ Patience: {self.patience_counter}/{self.config.PATIENCE}\")\n",
    "            \n",
    "            # Early stopping\n",
    "            if self.patience_counter >= self.config.PATIENCE:\n",
    "                print(f\"\\n‚ö†Ô∏è Early stopping activado en epoch {epoch+1}\")\n",
    "                print(f\"   Mejor val acc: {self.best_val_acc:.4f} (epoch {self.best_epoch+1})\")\n",
    "                break\n",
    "            \n",
    "            # Save checkpoint every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                checkpoint_path = self.config.MODELS_DIR / f'checkpoint_epoch_{epoch+1}.pth'\n",
    "                torch.save(checkpoint, checkpoint_path)\n",
    "                print(f\"üíæ Checkpoint guardado: {checkpoint_path}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"‚úÖ ENTRENAMIENTO COMPLETADO\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Mejor modelo: Epoch {self.best_epoch+1}\")\n",
    "        print(f\"  Val Accuracy: {self.best_val_acc:.4f}\")\n",
    "        print(f\"  Val F1-Score: {self.best_val_f1:.4f}\")\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "\n",
    "def create_optimizer_and_scheduler(model, train_loader, config):\n",
    "    \"\"\"Crea optimizer y scheduler optimizados\"\"\"\n",
    "    \n",
    "    # Separar par√°metros para diferentes learning rates\n",
    "    # Backbone: LR m√°s bajo\n",
    "    # Heads: LR m√°s alto\n",
    "    \n",
    "    backbone_params = []\n",
    "    head_params = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'image_model' in name:\n",
    "            backbone_params.append(param)\n",
    "        else:\n",
    "            head_params.append(param)\n",
    "    \n",
    "    # Optimizer: AdamW con weight decay\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': backbone_params, 'lr': config.LEARNING_RATE * 0.1},  # 10x menor para backbone\n",
    "        {'params': head_params, 'lr': config.LEARNING_RATE}\n",
    "    ], weight_decay=config.WEIGHT_DECAY)\n",
    "    \n",
    "    # Scheduler: Cosine Annealing con Warmup\n",
    "    num_training_steps = len(train_loader) * config.EPOCHS\n",
    "    num_warmup_steps = len(train_loader) * config.WARMUP_EPOCHS\n",
    "    \n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            # Linear warmup\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        # Cosine annealing\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + np.cos(np.pi * progress)))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    # Alternativa: ReduceLROnPlateau\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, mode='min', factor=0.5, patience=5, verbose=True, min_lr=config.MIN_LR\n",
    "    # )\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training loop y optimizaci√≥n configurados\")\n",
    "print(\"   - AdamW optimizer con differential learning rates\")\n",
    "print(\"   - Cosine annealing con warmup\")\n",
    "print(\"   - Gradient clipping\")\n",
    "print(\"   - Automatic Mixed Precision (AMP)\")\n",
    "print(\"   - Early stopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGN√ìSTICO COMPLETO DE DATOS\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Para ver errores exactos\n",
    "\n",
    "print(\"üîç DIAGN√ìSTICO COMPLETO DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Verificar estructura del dataset\n",
    "print(\"\\nüì¶ Verificando primer batch del train_loader...\")\n",
    "try:\n",
    "    test_batch = next(iter(train_loader))\n",
    "    print(f\"‚úÖ Batch cargado exitosamente\")\n",
    "    print(f\"\\nShapes:\")\n",
    "    print(f\"   Images: {test_batch['image'].shape}\")\n",
    "    print(f\"   Metadata: {test_batch['metadata'].shape}\")\n",
    "    print(f\"   Labels: {test_batch['label'].shape}\")\n",
    "    \n",
    "    # Verificar rangos\n",
    "    print(f\"\\nRangos de valores:\")\n",
    "    print(f\"   Images: [{test_batch['image'].min():.3f}, {test_batch['image'].max():.3f}]\")\n",
    "    print(f\"   Metadata: [{test_batch['metadata'].min():.3f}, {test_batch['metadata'].max():.3f}]\")\n",
    "    print(f\"   Labels: [{test_batch['label'].min()}, {test_batch['label'].max()}]\")\n",
    "    \n",
    "    # CR√çTICO: Verificar que labels est√°n en rango correcto\n",
    "    max_label = test_batch['label'].max().item()\n",
    "    print(f\"\\nüéØ Verificaci√≥n de labels:\")\n",
    "    print(f\"   Max label en batch: {max_label}\")\n",
    "    print(f\"   Num classes esperado: {num_classes}\")\n",
    "    \n",
    "    if max_label >= num_classes:\n",
    "        print(f\"   ‚ùå ERROR CR√çTICO: Label {max_label} >= num_classes {num_classes}\")\n",
    "        print(f\"   Las labels deben estar en rango [0, {num_classes-1}]\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Labels en rango correcto [0, {num_classes-1}]\")\n",
    "    \n",
    "    # 2. Verificar dimensiones categ√≥ricas\n",
    "    print(f\"\\nüìä Verificando categorical dimensions:\")\n",
    "    print(f\"   Total categorical features: {len(preprocessor.categorical_features)}\")\n",
    "    print(f\"   Categorical dims: {preprocessor.categorical_dims}\")\n",
    "    \n",
    "    # 3. Verificar que cat_feature_indices coincide con categorical_dims\n",
    "    print(f\"\\nüîë Verificando cat_feature_indices:\")\n",
    "    print(f\"   cat_feature_indices keys: {list(cat_feature_indices.keys())}\")\n",
    "    print(f\"   categorical_dims keys: {list(preprocessor.categorical_dims.keys())}\")\n",
    "    \n",
    "    if set(cat_feature_indices.keys()) != set(preprocessor.categorical_dims.keys()):\n",
    "        print(f\"   ‚ùå ERROR: Las keys no coinciden!\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Keys coinciden correctamente\")\n",
    "    \n",
    "    # 4. Verificar valores categ√≥ricos en el batch\n",
    "    metadata_batch = test_batch['metadata']\n",
    "    print(f\"\\nüìä Verificando valores categ√≥ricos en metadata:\")\n",
    "    \n",
    "    cat_start_idx = 0\n",
    "    for feat_name in preprocessor.categorical_features:\n",
    "        if feat_name in preprocessor.categorical_dims:\n",
    "            max_dim = preprocessor.categorical_dims[feat_name]\n",
    "            col_values = metadata_batch[:, cat_start_idx]\n",
    "            min_val = col_values.min().item()\n",
    "            max_val = col_values.max().item()\n",
    "            \n",
    "            print(f\"   {feat_name}: range=[{min_val:.0f}, {max_val:.0f}], dim={max_dim}\")\n",
    "            \n",
    "            if max_val >= max_dim:\n",
    "                print(f\"      ‚ùå ERROR: Valor {max_val:.0f} >= dim {max_dim}\")\n",
    "            \n",
    "            cat_start_idx += 1\n",
    "    \n",
    "    # 5. PRUEBA CR√çTICA: Intentar forward pass\n",
    "    print(f\"\\nüß™ PRUEBA DE FORWARD PASS:\")\n",
    "    try:\n",
    "        images = test_batch['image'].to(device)\n",
    "        metadata = test_batch['metadata'].to(device)\n",
    "        labels = test_batch['label'].to(device)\n",
    "        \n",
    "        print(f\"   Datos movidos a GPU...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print(f\"   Intentando forward pass...\")\n",
    "            logits = model(images, metadata, cat_feature_indices)\n",
    "            print(f\"   ‚úÖ Forward pass exitoso!\")\n",
    "            print(f\"   Output shape: {logits.shape}\")\n",
    "            \n",
    "            # Verificar que la salida tiene el n√∫mero correcto de clases\n",
    "            if logits.shape[1] != num_classes:\n",
    "                print(f\"   ‚ùå ERROR: Output tiene {logits.shape[1]} clases, esperado {num_classes}\")\n",
    "            else:\n",
    "                print(f\"   ‚úÖ Output correcto: {num_classes} clases\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ERROR en forward pass:\")\n",
    "        print(f\"   {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    \n",
    "    del test_batch\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error cargando batch:\")\n",
    "    print(f\"   {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Diagn√≥stico completado\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9896a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 9: EJECUTAR ENTRENAMIENTO\n",
    "# ============================================================================\n",
    "\n",
    "# Crear modelo\n",
    "print(\"üèóÔ∏è Creando modelo...\")\n",
    "model = create_model(\n",
    "    num_classes=num_classes,\n",
    "    categorical_dims=preprocessor.categorical_dims,\n",
    "    num_numerical_features=len(preprocessor.numerical_features)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Contar par√°metros\n",
    "trainable_params, total_params = count_parameters(model)\n",
    "print(f\"\\nüìä Par√°metros del modelo:\")\n",
    "print(f\"   Total: {total_params:,}\")\n",
    "print(f\"   Entrenables: {trainable_params:,}\")\n",
    "print(f\"   No entrenables: {total_params - trainable_params:,}\")\n",
    "\n",
    "# Crear loss function\n",
    "criterion = CombinedLoss(\n",
    "    class_weights=class_weights,\n",
    "    focal_gamma=2.0,\n",
    "    label_smoothing=0.1\n",
    ")\n",
    "\n",
    "print(f\"\\nüéØ Loss function: Combined (Focal + Label Smoothing)\")\n",
    "\n",
    "# Crear optimizer y scheduler\n",
    "optimizer, scheduler = create_optimizer_and_scheduler(model, train_loader, Config)\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è Optimizer: AdamW\")\n",
    "print(f\"   Learning rate (backbone): {Config.LEARNING_RATE * 0.1:.2e}\")\n",
    "print(f\"   Learning rate (heads): {Config.LEARNING_RATE:.2e}\")\n",
    "print(f\"   Weight decay: {Config.WEIGHT_DECAY:.2e}\")\n",
    "print(f\"\\nüìÖ Scheduler: Cosine Annealing con Warmup\")\n",
    "print(f\"   Warmup epochs: {Config.WARMUP_EPOCHS}\")\n",
    "print(f\"   Total epochs: {Config.EPOCHS}\")\n",
    "\n",
    "# Crear trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    cat_indices=cat_feature_indices,\n",
    "    device=device,\n",
    "    config=Config\n",
    ")\n",
    "\n",
    "# ENTRENAR\n",
    "history = trainer.train()\n",
    "\n",
    "# Guardar history\n",
    "with open(Config.OUTPUT_DIR / 'training_history.json', 'w') as f:\n",
    "    # Convertir history a formato serializable\n",
    "    history_serializable = {\n",
    "        k: [float(v) if isinstance(v, (np.floating, float)) else v for v in vals]\n",
    "        for k, vals in history.items()\n",
    "    }\n",
    "    json.dump(history_serializable, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Training history guardado\")\n",
    "\n",
    "# Visualizar training history\n",
    "plot_training_history(history, save_path=Config.OUTPUT_DIR / 'training_curves.png')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ ENTRENAMIENTO FINALIZADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799de53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 10: EVALUACI√ìN CON TEST-TIME AUGMENTATION (TTA)\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_with_tta(model, dataloader, cat_indices, device, tta_transforms=5):\n",
    "    \"\"\"Eval√∫a el modelo con TTA\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    tta_augmenter = TTATransform(img_size=Config.IMG_SIZE)\n",
    "    \n",
    "    print(f\"üîç Evaluando con TTA ({tta_transforms} augmentations)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='TTA Evaluation'):\n",
    "            images_orig = batch['image']\n",
    "            metadata = batch['metadata'].to(device)\n",
    "            labels = batch['label']\n",
    "            \n",
    "            batch_size = images_orig.size(0)\n",
    "            tta_probs = []\n",
    "            \n",
    "            # Para cada imagen en el batch\n",
    "            for i in range(batch_size):\n",
    "                img_path = dataloader.dataset.image_paths[i]\n",
    "                img_pil = Image.open(img_path).convert('RGB')\n",
    "                \n",
    "                # Aplicar TTA transforms\n",
    "                tta_images = tta_augmenter(img_pil)\n",
    "                \n",
    "                # Promediar predicciones\n",
    "                img_probs = []\n",
    "                for tta_img in tta_images:\n",
    "                    tta_img_batch = tta_img.unsqueeze(0).to(device)\n",
    "                    meta_batch = metadata[i:i+1]\n",
    "                    \n",
    "                    with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                        logits = model(tta_img_batch, meta_batch, cat_indices)\n",
    "                        probs = F.softmax(logits, dim=1)\n",
    "                    \n",
    "                    img_probs.append(probs.cpu())\n",
    "                \n",
    "                # Promediar probabilidades de todas las augmentations\n",
    "                avg_probs = torch.stack(img_probs).mean(dim=0)\n",
    "                tta_probs.append(avg_probs)\n",
    "            \n",
    "            # Stack batch probabilities\n",
    "            batch_probs = torch.cat(tta_probs, dim=0)\n",
    "            batch_preds = torch.argmax(batch_probs, dim=1)\n",
    "            \n",
    "            all_probs.append(batch_probs)\n",
    "            all_preds.append(batch_preds)\n",
    "            all_targets.append(labels)\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_probs = torch.cat(all_probs, dim=0).numpy()\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "    \n",
    "    return all_preds, all_probs, all_targets\n",
    "\n",
    "\n",
    "def evaluate_standard(model, dataloader, cat_indices, device):\n",
    "    \"\"\"Evaluaci√≥n est√°ndar sin TTA\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    print(f\"üîç Evaluando (est√°ndar)...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Standard Evaluation'):\n",
    "            images = batch['image'].to(device)\n",
    "            metadata = batch['metadata'].to(device)\n",
    "            labels = batch['label']\n",
    "            \n",
    "            with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                logits = model(images, metadata, cat_indices)\n",
    "                probs = F.softmax(logits, dim=1)\n",
    "            \n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            all_probs.append(probs.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_targets.append(labels)\n",
    "    \n",
    "    all_probs = torch.cat(all_probs, dim=0).numpy()\n",
    "    all_preds = torch.cat(all_preds, dim=0).numpy()\n",
    "    all_targets = torch.cat(all_targets, dim=0).numpy()\n",
    "    \n",
    "    return all_preds, all_probs, all_targets\n",
    "\n",
    "\n",
    "# Cargar mejor modelo\n",
    "print(\"üì• Cargando mejor modelo...\")\n",
    "checkpoint = torch.load(Config.MODELS_DIR / 'best_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úÖ Modelo cargado (Epoch {checkpoint['epoch']+1})\")\n",
    "\n",
    "# ===== EVALUACI√ìN EN VALIDATION SET =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EVALUACI√ìN EN VALIDATION SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sin TTA\n",
    "val_preds, val_probs, val_targets = evaluate_standard(model, val_loader, cat_feature_indices, device)\n",
    "\n",
    "val_acc = accuracy_score(val_targets, val_preds)\n",
    "val_f1_weighted = f1_score(val_targets, val_preds, average='weighted')\n",
    "val_f1_macro = f1_score(val_targets, val_preds, average='macro')\n",
    "\n",
    "print(f\"\\nüìà Resultados (Sin TTA):\")\n",
    "print(f\"   Accuracy: {val_acc:.4f}\")\n",
    "print(f\"   F1-Score (weighted): {val_f1_weighted:.4f}\")\n",
    "print(f\"   F1-Score (macro): {val_f1_macro:.4f}\")\n",
    "\n",
    "# Con TTA\n",
    "val_preds_tta, val_probs_tta, val_targets_tta = evaluate_with_tta(\n",
    "    model, val_loader, cat_feature_indices, device, tta_transforms=Config.TTA_TRANSFORMS\n",
    ")\n",
    "\n",
    "val_acc_tta = accuracy_score(val_targets_tta, val_preds_tta)\n",
    "val_f1_weighted_tta = f1_score(val_targets_tta, val_preds_tta, average='weighted')\n",
    "val_f1_macro_tta = f1_score(val_targets_tta, val_preds_tta, average='macro')\n",
    "\n",
    "print(f\"\\nüìà Resultados (Con TTA):\")\n",
    "print(f\"   Accuracy: {val_acc_tta:.4f} ({'+' if val_acc_tta > val_acc else ''}{val_acc_tta - val_acc:+.4f})\")\n",
    "print(f\"   F1-Score (weighted): {val_f1_weighted_tta:.4f} ({'+' if val_f1_weighted_tta > val_f1_weighted else ''}{val_f1_weighted_tta - val_f1_weighted:+.4f})\")\n",
    "print(f\"   F1-Score (macro): {val_f1_macro_tta:.4f} ({'+' if val_f1_macro_tta > val_f1_macro else ''}{val_f1_macro_tta - val_f1_macro:+.4f})\")\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm_val = confusion_matrix(val_targets_tta, val_preds_tta)\n",
    "plot_confusion_matrix(cm_val, class_names, save_path=Config.OUTPUT_DIR / 'confusion_matrix_val.png')\n",
    "\n",
    "# ===== EVALUACI√ìN EN TEST SET =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä EVALUACI√ìN FINAL EN TEST SET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sin TTA\n",
    "test_preds, test_probs, test_targets = evaluate_standard(model, test_loader, cat_feature_indices, device)\n",
    "\n",
    "test_acc = accuracy_score(test_targets, test_preds)\n",
    "test_f1_weighted = f1_score(test_targets, test_preds, average='weighted')\n",
    "test_f1_macro = f1_score(test_targets, test_preds, average='macro')\n",
    "\n",
    "print(f\"\\nüìà Resultados (Sin TTA):\")\n",
    "print(f\"   Accuracy: {test_acc:.4f}\")\n",
    "print(f\"   F1-Score (weighted): {test_f1_weighted:.4f}\")\n",
    "print(f\"   F1-Score (macro): {test_f1_macro:.4f}\")\n",
    "\n",
    "# Con TTA\n",
    "test_preds_tta, test_probs_tta, test_targets_tta = evaluate_with_tta(\n",
    "    model, test_loader, cat_feature_indices, device, tta_transforms=Config.TTA_TRANSFORMS\n",
    ")\n",
    "\n",
    "test_acc_tta = accuracy_score(test_targets_tta, test_preds_tta)\n",
    "test_f1_weighted_tta = f1_score(test_targets_tta, test_preds_tta, average='weighted')\n",
    "test_f1_macro_tta = f1_score(test_targets_tta, test_preds_tta, average='macro')\n",
    "test_precision_tta = precision_score(test_targets_tta, test_preds_tta, average='weighted')\n",
    "test_recall_tta = recall_score(test_targets_tta, test_preds_tta, average='weighted')\n",
    "\n",
    "print(f\"\\nüìà Resultados (Con TTA):\")\n",
    "print(f\"   Accuracy: {test_acc_tta:.4f} ({'+' if test_acc_tta > test_acc else ''}{test_acc_tta - test_acc:+.4f})\")\n",
    "print(f\"   Precision (weighted): {test_precision_tta:.4f}\")\n",
    "print(f\"   Recall (weighted): {test_recall_tta:.4f}\")\n",
    "print(f\"   F1-Score (weighted): {test_f1_weighted_tta:.4f} ({'+' if test_f1_weighted_tta > test_f1_weighted else ''}{test_f1_weighted_tta - test_f1_weighted:+.4f})\")\n",
    "print(f\"   F1-Score (macro): {test_f1_macro_tta:.4f} ({'+' if test_f1_macro_tta > test_f1_macro else ''}{test_f1_macro_tta - test_f1_macro:+.4f})\")\n",
    "\n",
    "# Classification report detallado\n",
    "print(f\"\\nüìã Classification Report:\")\n",
    "print(classification_report(test_targets_tta, test_preds_tta, target_names=class_names))\n",
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm_test = confusion_matrix(test_targets_tta, test_preds_tta)\n",
    "plot_confusion_matrix(cm_test, class_names, save_path=Config.OUTPUT_DIR / 'confusion_matrix_test.png')\n",
    "\n",
    "# Guardar resultados\n",
    "test_results = {\n",
    "    'test_accuracy': float(test_acc_tta),\n",
    "    'test_accuracy_no_tta': float(test_acc),\n",
    "    'test_precision': float(test_precision_tta),\n",
    "    'test_recall': float(test_recall_tta),\n",
    "    'test_f1_weighted': float(test_f1_weighted_tta),\n",
    "    'test_f1_macro': float(test_f1_macro_tta),\n",
    "    'per_class_metrics': {},\n",
    "    'confusion_matrix': cm_test.tolist()\n",
    "}\n",
    "\n",
    "# Per-class metrics\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = test_targets_tta == i\n",
    "    class_preds = test_preds_tta[class_mask]\n",
    "    class_targets = test_targets_tta[class_mask]\n",
    "    \n",
    "    if len(class_targets) > 0:\n",
    "        class_acc = accuracy_score(class_targets, class_preds)\n",
    "        test_results['per_class_metrics'][class_name] = {\n",
    "            'accuracy': float(class_acc),\n",
    "            'samples': int(len(class_targets))\n",
    "        }\n",
    "\n",
    "with open(Config.OUTPUT_DIR / 'test_results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Resultados de test guardados\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ EVALUACI√ìN COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüéØ RESULTADO FINAL:\")\n",
    "print(f\"   Test Accuracy (con TTA): {test_acc_tta:.4f} ({test_acc_tta*100:.2f}%)\")\n",
    "print(f\"   Test F1-Score (weighted): {test_f1_weighted_tta:.4f}\")\n",
    "print(f\"   Mejora con TTA: +{(test_acc_tta - test_acc)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 11: INFERENCIA Y PREDICCI√ìN EN NUEVAS IM√ÅGENES\n",
    "# ============================================================================\n",
    "\n",
    "class SkinCancerPredictor:\n",
    "    \"\"\"Predictor para nuevas im√°genes\"\"\"\n",
    "    \n",
    "    def __init__(self, model, preprocessor, cat_indices, class_names, device, use_tta=True):\n",
    "        self.model = model\n",
    "        self.preprocessor = preprocessor\n",
    "        self.cat_indices = cat_indices\n",
    "        self.class_names = class_names\n",
    "        self.device = device\n",
    "        self.use_tta = use_tta\n",
    "        \n",
    "        self.transform = AdvancedAugmentation(img_size=Config.IMG_SIZE, mode='val')\n",
    "        self.tta_transform = TTATransform(img_size=Config.IMG_SIZE) if use_tta else None\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "    def predict_single(self, image_path, metadata_dict):\n",
    "        \"\"\"\n",
    "        Predice una sola imagen\n",
    "        \n",
    "        Args:\n",
    "            image_path: ruta a la imagen\n",
    "            metadata_dict: diccionario con metadatos (mismo formato que CSV)\n",
    "        \n",
    "        Returns:\n",
    "            dict con predicci√≥n, probabilidades y confianza\n",
    "        \"\"\"\n",
    "        # Preprocesar metadata\n",
    "        metadata_df = pd.DataFrame([metadata_dict])\n",
    "        metadata_processed, _ = self.preprocessor.transform(metadata_df)\n",
    "        metadata_tensor = torch.FloatTensor(metadata_processed).to(self.device)\n",
    "        \n",
    "        # Cargar imagen\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if self.use_tta and self.tta_transform is not None:\n",
    "                # TTA\n",
    "                tta_images = self.tta_transform(image)\n",
    "                tta_probs = []\n",
    "                \n",
    "                for tta_img in tta_images:\n",
    "                    tta_img_batch = tta_img.unsqueeze(0).to(self.device)\n",
    "                    \n",
    "                    with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                        logits = self.model(tta_img_batch, metadata_tensor, self.cat_indices)\n",
    "                        probs = F.softmax(logits, dim=1)\n",
    "                    \n",
    "                    tta_probs.append(probs.cpu())\n",
    "                \n",
    "                # Promediar probabilidades\n",
    "                avg_probs = torch.stack(tta_probs).mean(dim=0)\n",
    "            else:\n",
    "                # Predicci√≥n est√°ndar\n",
    "                img_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "                \n",
    "                with torch.cuda.amp.autocast(enabled=Config.AMP_ENABLED):\n",
    "                    logits = self.model(img_tensor, metadata_tensor, self.cat_indices)\n",
    "                    avg_probs = F.softmax(logits, dim=1).cpu()\n",
    "        \n",
    "        # Obtener predicci√≥n\n",
    "        pred_class_idx = torch.argmax(avg_probs, dim=1).item()\n",
    "        pred_class_name = self.class_names[pred_class_idx]\n",
    "        confidence = avg_probs[0, pred_class_idx].item()\n",
    "        \n",
    "        # Todas las probabilidades\n",
    "        class_probs = {\n",
    "            name: float(avg_probs[0, i].item())\n",
    "            for i, name in enumerate(self.class_names)\n",
    "        }\n",
    "        \n",
    "        result = {\n",
    "            'predicted_class': pred_class_name,\n",
    "            'predicted_class_idx': pred_class_idx,\n",
    "            'confidence': confidence,\n",
    "            'class_probabilities': class_probs,\n",
    "            'top_3_predictions': sorted(\n",
    "                class_probs.items(),\n",
    "                key=lambda x: x[1],\n",
    "                reverse=True\n",
    "            )[:3]\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def predict_batch(self, image_paths, metadata_dicts):\n",
    "        \"\"\"Predice m√∫ltiples im√°genes\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for img_path, meta_dict in tqdm(zip(image_paths, metadata_dicts), \n",
    "                                        total=len(image_paths),\n",
    "                                        desc='Prediciendo'):\n",
    "            result = self.predict_single(img_path, meta_dict)\n",
    "            results.append(result)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def visualize_prediction(self, image_path, metadata_dict, save_path=None):\n",
    "        \"\"\"Visualiza predicci√≥n con probabilidades\"\"\"\n",
    "        result = self.predict_single(image_path, metadata_dict)\n",
    "        \n",
    "        # Crear figura\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        # Mostrar imagen\n",
    "        img = Image.open(image_path)\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].axis('off')\n",
    "        axes[0].set_title(f'Predicci√≥n: {result[\"predicted_class\"]}\\n'\n",
    "                         f'Confianza: {result[\"confidence\"]:.2%}',\n",
    "                         fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Mostrar probabilidades\n",
    "        probs = result['class_probabilities']\n",
    "        classes = list(probs.keys())\n",
    "        values = list(probs.values())\n",
    "        \n",
    "        colors = ['green' if c == result['predicted_class'] else 'steelblue' \n",
    "                 for c in classes]\n",
    "        \n",
    "        axes[1].barh(classes, values, color=colors)\n",
    "        axes[1].set_xlabel('Probabilidad', fontsize=12)\n",
    "        axes[1].set_title('Probabilidades por Clase', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_xlim(0, 1)\n",
    "        \n",
    "        for i, (c, v) in enumerate(zip(classes, values)):\n",
    "            axes[1].text(v + 0.01, i, f'{v:.3f}', va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Imprimir resultado detallado\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"PREDICCI√ìN DETALLADA\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Clase predicha: {result['predicted_class']}\")\n",
    "        print(f\"Confianza: {result['confidence']:.2%}\")\n",
    "        print(f\"\\nTop 3 predicciones:\")\n",
    "        for i, (cls, prob) in enumerate(result['top_3_predictions'], 1):\n",
    "            print(f\"  {i}. {cls}: {prob:.2%}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# Crear predictor\n",
    "print(\"üîÆ Creando predictor...\")\n",
    "predictor = SkinCancerPredictor(\n",
    "    model=model,\n",
    "    preprocessor=preprocessor,\n",
    "    cat_indices=cat_feature_indices,\n",
    "    class_names=class_names,\n",
    "    device=device,\n",
    "    use_tta=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Predictor listo\")\n",
    "\n",
    "# ===== EJEMPLO DE USO =====\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EJEMPLO DE PREDICCI√ìN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Tomar una muestra del test set\n",
    "sample_idx = 0\n",
    "sample_img_path = test_dataset.image_paths[sample_idx]\n",
    "sample_metadata = df_processed.iloc[X_test[sample_idx]].to_dict()\n",
    "sample_true_label = class_names[test_dataset.labels[sample_idx].item()]\n",
    "\n",
    "print(f\"\\nImagen de ejemplo: {sample_img_path}\")\n",
    "print(f\"Diagn√≥stico real: {sample_true_label}\")\n",
    "\n",
    "# Predecir\n",
    "predictor.visualize_prediction(\n",
    "    sample_img_path,\n",
    "    sample_metadata,\n",
    "    save_path=Config.OUTPUT_DIR / 'example_prediction.png'\n",
    ")\n",
    "\n",
    "# ===== FUNCI√ìN PARA PREDICCI√ìN DE NUEVAS IM√ÅGENES =====\n",
    "def predict_new_image(image_path, metadata_dict=None):\n",
    "    \"\"\"\n",
    "    Funci√≥n helper para predecir nuevas im√°genes\n",
    "    \n",
    "    Args:\n",
    "        image_path: ruta a la imagen\n",
    "        metadata_dict: diccionario con metadatos (opcional, se usar√°n valores por defecto)\n",
    "    \n",
    "    Ejemplo:\n",
    "        metadata = {\n",
    "            'age': 45,\n",
    "            'gender': 'FEMALE',\n",
    "            'region': 'ARM',\n",
    "            'diameter_1': 5.0,\n",
    "            'diameter_2': 4.0,\n",
    "            'smoke': False,\n",
    "            'drink': False,\n",
    "            # ... m√°s campos\n",
    "        }\n",
    "        result = predict_new_image('path/to/image.png', metadata)\n",
    "    \"\"\"\n",
    "    if metadata_dict is None:\n",
    "        # Valores por defecto\n",
    "        metadata_dict = {\n",
    "            'age': 50,\n",
    "            'gender': 'UNKNOWN',\n",
    "            'region': 'UNKNOWN',\n",
    "            'smoke': 'UNKNOWN',\n",
    "            'drink': 'UNKNOWN',\n",
    "            'background_father': 'UNKNOWN',\n",
    "            'background_mother': 'UNKNOWN',\n",
    "            'pesticide': 'UNKNOWN',\n",
    "            'skin_cancer_history': 'UNKNOWN',\n",
    "            'cancer_history': 'UNKNOWN',\n",
    "            'has_piped_water': 'UNKNOWN',\n",
    "            'has_sewage_system': 'UNKNOWN',\n",
    "            'fitspatrick': 3.0,\n",
    "            'diameter_1': 5.0,\n",
    "            'diameter_2': 5.0,\n",
    "            'itch': False,\n",
    "            'grew': False,\n",
    "            'hurt': False,\n",
    "            'changed': False,\n",
    "            'bleed': False,\n",
    "            'elevation': False,\n",
    "            'biopsed': False\n",
    "        }\n",
    "    \n",
    "    result = predictor.predict_single(image_path, metadata_dict)\n",
    "    \n",
    "    # Visualizar\n",
    "    predictor.visualize_prediction(\n",
    "        image_path,\n",
    "        metadata_dict,\n",
    "        save_path=Config.OUTPUT_DIR / f'prediction_{Path(image_path).stem}.png'\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ SISTEMA DE PREDICCI√ìN LISTO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nPara predecir nuevas im√°genes, usa:\")\n",
    "print(\"  result = predict_new_image('path/to/image.png', metadata_dict)\")\n",
    "print(\"\\nDonde metadata_dict es un diccionario con los campos del CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7618022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELDA 12: RESUMEN Y AN√ÅLISIS FINAL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*20 + \"üèÜ RESUMEN DEL MODELO üèÜ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä ARQUITECTURA:\n",
    "   ‚Ä¢ Modelo de imagen: {Config.EFFICIENTNET_MODEL}\n",
    "   ‚Ä¢ Tama√±o de entrada: {Config.IMG_SIZE}x{Config.IMG_SIZE}\n",
    "   ‚Ä¢ TabTransformer: {Config.TAB_NUM_LAYERS} layers, {Config.TAB_NUM_HEADS} heads\n",
    "   ‚Ä¢ Fusi√≥n: Late fusion con MLP ({' -> '.join(map(str, Config.FUSION_HIDDEN_DIMS))})\n",
    "   ‚Ä¢ Par√°metros totales: {total_params:,}\n",
    "   ‚Ä¢ Par√°metros entrenables: {trainable_params:,}\n",
    "\n",
    "üéØ T√âCNICAS APLICADAS:\n",
    "   ‚úì EfficientNetV2-M pre-entrenado\n",
    "   ‚úì TabTransformer para metadatos tabulares\n",
    "   ‚úì Late Fusion multimodal\n",
    "   ‚úì Augmentations avanzadas (geom√©tricas, colorim√©tricas, √≥pticas)\n",
    "   ‚úì Mixup & CutMix durante entrenamiento\n",
    "   ‚úì Combined Loss (Focal + Label Smoothing)\n",
    "   ‚úì Class weighting para desbalanceo\n",
    "   ‚úì Differential learning rates (backbone vs heads)\n",
    "   ‚úì Cosine Annealing con Warmup\n",
    "   ‚úì Gradient clipping\n",
    "   ‚úì Automatic Mixed Precision (AMP)\n",
    "   ‚úì Early stopping\n",
    "   ‚úì Test-Time Augmentation (TTA)\n",
    "   \n",
    "üìà RESULTADOS:\n",
    "   ‚Ä¢ Val Accuracy: {checkpoint['best_val_acc']:.4f} ({checkpoint['best_val_acc']*100:.2f}%)\n",
    "   ‚Ä¢ Test Accuracy (sin TTA): {test_acc:.4f} ({test_acc*100:.2f}%)\n",
    "   ‚Ä¢ Test Accuracy (con TTA): {test_acc_tta:.4f} ({test_acc_tta*100:.2f}%)\n",
    "   ‚Ä¢ Test F1-Score: {test_f1_weighted_tta:.4f}\n",
    "   ‚Ä¢ Mejora con TTA: +{(test_acc_tta - test_acc)*100:.2f}%\n",
    "   \n",
    "üíæ ARCHIVOS GENERADOS:\n",
    "   ‚Ä¢ {Config.MODELS_DIR / 'best_model.pth'}\n",
    "   ‚Ä¢ {Config.OUTPUT_DIR / 'metadata_preprocessor.pkl'}\n",
    "   ‚Ä¢ {Config.OUTPUT_DIR / 'training_history.json'}\n",
    "   ‚Ä¢ {Config.OUTPUT_DIR / 'test_results.json'}\n",
    "   ‚Ä¢ {Config.OUTPUT_DIR / 'training_curves.png'}\n",
    "   ‚Ä¢ {Config.OUTPUT_DIR / 'confusion_matrix_test.png'}\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*15 + \"üöÄ T√âCNICAS PARA MEJORAR RENDIMIENTO üöÄ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "Si quieres mejorar a√∫n m√°s el modelo (objetivo: 98%+), considera:\n",
    "\n",
    "1. üì∏ DATOS Y AUGMENTATION:\n",
    "   ‚Ä¢ Aumentar resoluci√≥n a 640px (requiere m√°s GPU memory)\n",
    "   ‚Ä¢ Agregar m√°s augmentations espec√≠ficas para dermatolog√≠a:\n",
    "     - Simulaci√≥n de diferentes iluminaciones (dermoscopia)\n",
    "     - Simulaci√≥n de vello (hair occlusion)\n",
    "     - Ajustes de contraste espec√≠ficos para lesiones\n",
    "   ‚Ä¢ Recolectar m√°s datos (especialmente de clases minoritarias)\n",
    "   ‚Ä¢ Usar pseudo-labeling con datos no etiquetados\n",
    "\n",
    "2. üèóÔ∏è ARQUITECTURA:\n",
    "   ‚Ä¢ Ensembling de m√∫ltiples modelos:\n",
    "     - EfficientNetV2-L + ConvNeXt + Swin Transformer\n",
    "   ‚Ä¢ Attention mechanisms m√°s sofisticados:\n",
    "     - CBAM (Convolutional Block Attention Module)\n",
    "     - Squeeze-and-Excitation\n",
    "   ‚Ä¢ Cross-attention entre imagen y metadatos\n",
    "\n",
    "3. üéì ENTRENAMIENTO:\n",
    "   ‚Ä¢ Progressive resizing (empezar con 224px, luego 384px, finalmente 512px)\n",
    "   ‚Ä¢ Two-stage training:\n",
    "     - Stage 1: Solo clasificaci√≥n b√°sica\n",
    "     - Stage 2: Fine-tuning con metadatos\n",
    "   ‚Ä¢ Knowledge distillation de modelos grandes\n",
    "   ‚Ä¢ Self-supervised pre-training en datos de dermatolog√≠a\n",
    "\n",
    "4. üîß OPTIMIZACI√ìN:\n",
    "   ‚Ä¢ Usar SAM optimizer (Sharpness-Aware Minimization)\n",
    "   ‚Ä¢ Stochastic Weight Averaging (SWA)\n",
    "   ‚Ä¢ Gradient accumulation para batches m√°s grandes\n",
    "   ‚Ä¢ FP16/BF16 training completo\n",
    "\n",
    "5. üìä POST-PROCESSING:\n",
    "   ‚Ä¢ Calibraci√≥n de probabilidades (Temperature Scaling, Platt Scaling)\n",
    "   ‚Ä¢ Threshold optimization por clase\n",
    "   ‚Ä¢ Ensembling con diferentes seeds\n",
    "   ‚Ä¢ TTA m√°s agresivo (m√°s transformaciones)\n",
    "\n",
    "6. üîç AN√ÅLISIS DE ERRORES:\n",
    "   ‚Ä¢ Identificar clases confusas y aplicar t√©cnicas espec√≠ficas\n",
    "   ‚Ä¢ An√°lisis de muestras mal clasificadas\n",
    "   ‚Ä¢ Feature importance analysis\n",
    "   ‚Ä¢ GradCAM para interpretabilidad\n",
    "\n",
    "7. üéØ T√âCNICAS ESPEC√çFICAS PARA DESBALANCEO:\n",
    "   ‚Ä¢ Focal Loss con diferentes gammas por clase\n",
    "   ‚Ä¢ Class-balanced Loss\n",
    "   ‚Ä¢ Oversampling m√°s agresivo con ADASYN\n",
    "   ‚Ä¢ Crear muestras sint√©ticas con GANs\n",
    "\n",
    "8. üí° METADATA ENGINEERING:\n",
    "   ‚Ä¢ Extraer features autom√°ticas de las im√°genes:\n",
    "     - Descriptores de color (histogramas HSV)\n",
    "     - Textura (Haralick features, LBP)\n",
    "     - Forma (momentos de Hu, contornos)\n",
    "   ‚Ä¢ Combinar con metadatos cl√≠nicos\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*25 + \"üìù C√ìDIGO DE EJEMPLO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "# EJEMPLO 1: Entrenar con resoluci√≥n m√°s alta\n",
    "Config.IMG_SIZE = 640\n",
    "Config.BATCH_SIZE = 8  # Reducir batch size\n",
    "\n",
    "# EJEMPLO 2: Ensembling de modelos\n",
    "models = [\n",
    "    create_model(..., img_model_name='tf_efficientnetv2_l'),\n",
    "    create_model(..., img_model_name='convnext_base'),\n",
    "    create_model(..., img_model_name='swin_base_patch4_window7_224')\n",
    "]\n",
    "\n",
    "def ensemble_predict(models, image, metadata):\n",
    "    probs = []\n",
    "    for model in models:\n",
    "        logits = model(image, metadata, cat_indices)\n",
    "        prob = F.softmax(logits, dim=1)\n",
    "        probs.append(prob)\n",
    "    return torch.stack(probs).mean(dim=0)\n",
    "\n",
    "# EJEMPLO 3: Progressive resizing\n",
    "# Stage 1: 224px, 30 epochs\n",
    "# Stage 2: 384px, 20 epochs  \n",
    "# Stage 3: 512px, 20 epochs\n",
    "\n",
    "# EJEMPLO 4: Pseudo-labeling\n",
    "# 1. Entrenar modelo inicial\n",
    "# 2. Predecir en datos no etiquetados con alta confianza\n",
    "# 3. Agregar predicciones confiables al training set\n",
    "# 4. Re-entrenar\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" \"*20 + \"‚úÖ SISTEMA COMPLETO Y LISTO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar resumen final\n",
    "summary = {\n",
    "    'model_config': {\n",
    "        'image_model': Config.EFFICIENTNET_MODEL,\n",
    "        'img_size': Config.IMG_SIZE,\n",
    "        'batch_size': Config.BATCH_SIZE,\n",
    "        'epochs_trained': checkpoint['epoch'] + 1,\n",
    "    },\n",
    "    'results': {\n",
    "        'best_val_acc': float(checkpoint['best_val_acc']),\n",
    "        'best_val_f1': float(checkpoint['best_val_f1']),\n",
    "        'test_acc_no_tta': float(test_acc),\n",
    "        'test_acc_tta': float(test_acc_tta),\n",
    "        'test_f1_weighted': float(test_f1_weighted_tta),\n",
    "        'test_f1_macro': float(test_f1_macro_tta),\n",
    "        'tta_improvement': float((test_acc_tta - test_acc) * 100)\n",
    "    },\n",
    "    'techniques': [\n",
    "        'EfficientNetV2-M pre-trained',\n",
    "        'TabTransformer for metadata',\n",
    "        'Late Fusion',\n",
    "        'Advanced Augmentations',\n",
    "        'Mixup & CutMix',\n",
    "        'Combined Loss (Focal + Label Smoothing)',\n",
    "        'Class Weighting',\n",
    "        'Differential Learning Rates',\n",
    "        'Cosine Annealing with Warmup',\n",
    "        'Gradient Clipping',\n",
    "        'Automatic Mixed Precision',\n",
    "        'Early Stopping',\n",
    "        'Test-Time Augmentation'\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open(Config.OUTPUT_DIR / 'final_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Resumen final guardado en: {Config.OUTPUT_DIR / 'final_summary.json'}\")\n",
    "print(f\"\\nüéâ ¬°Entrenamiento completado con √©xito!\")\n",
    "print(f\"   Accuracy final: {test_acc_tta*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec542bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
